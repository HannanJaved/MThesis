{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Imports\n",
    "# ------------------------------------------------------------------\n",
    "# Basic data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Graph data processing libraries\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Libraries for (G)NNs\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch.nn as nn\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------------------------\n",
    "def show_df_info(df):\n",
    "    print(df.info())\n",
    "    print('####### Repeat ####### \\n', df.duplicated().any())\n",
    "    print('####### Count ####### \\n', df.nunique())\n",
    "    print('####### Example ####### \\n',df.head())\n",
    "\n",
    "def label_statics(label_df, label_list):\n",
    "    print(\"####### nCount #######\")\n",
    "    for label in label_list:\n",
    "        print(label_df[label].value_counts())\n",
    "    print(\"####### nPercent #######\")\n",
    "    for label in label_list:\n",
    "        print(label_df[label].value_counts()/label_df.shape[0])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Data stuff\n",
    "# ------------------------------------------------------------------\n",
    "base_path = os.getcwd()\n",
    "input_ali_data_path = os.path.join(base_path, \"input_ali_data\")\n",
    "\n",
    "# Load the data files\n",
    "user_labels_path = os.path.join(input_ali_data_path, \"user_labels.csv\")\n",
    "user_edges_path = os.path.join(input_ali_data_path, \"user_edge.csv\")\n",
    "\n",
    "# Create dataframes to store the information from the .csv files\n",
    "user_labels = pd.read_csv(user_labels_path)\n",
    "user_edges = pd.read_csv(user_edges_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_age\n",
      "0    95375\n",
      "1    71583\n",
      "Name: count, dtype: int64\n",
      "71583\n"
     ]
    }
   ],
   "source": [
    "# Count the number of instances for each gender\n",
    "gender_counts = user_labels['gender'].value_counts()\n",
    "print(gender_counts)\n",
    "\n",
    "# Find the minimum count between the two genders\n",
    "min_count = min(gender_counts)\n",
    "print(min_count)\n",
    "\n",
    "# Sample an equal number of instances for each gender\n",
    "balanced_data = pd.concat([\n",
    "    user_labels[user_labels['gender'] == 1].sample(min_count),\n",
    "    user_labels[user_labels['gender'] == 0].sample(min_count)\n",
    "])\n",
    "\n",
    "# Reset the index of the balanced data\n",
    "balanced_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Update the user_labels dataframe with the balanced data\n",
    "filtered_user_labels = balanced_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           uid  gender  age  buy  student  city  bin_age  bin_buy\n",
      "0       156829       0    2    1        1     0        1        1\n",
      "1        87623       1    2    0        1     0        1        0\n",
      "2        21014       0    1    1        1     0        1        1\n",
      "3        60909       0    3    1        1     2        1        1\n",
      "4        60957       1    3    1        1     1        1        1\n",
      "...        ...     ...  ...  ...      ...   ...      ...      ...\n",
      "143161   56205       1    0    1        0     0        0        1\n",
      "143162  144496       0    0    1        1     0        0        1\n",
      "143163   38241       0    4    1        1     0        0        1\n",
      "143164   85503       1    0    0        1     3        0        0\n",
      "143165  158306       0    0    0        1     3        0        0\n",
      "\n",
      "[143166 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(balanced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84384 entries, 0 to 84383\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   uid      84384 non-null  int64\n",
      " 1   gender   84384 non-null  int64\n",
      " 2   age      84384 non-null  int64\n",
      " 3   buy      84384 non-null  int64\n",
      " 4   student  84384 non-null  int64\n",
      " 5   city     84384 non-null  int64\n",
      " 6   bin_age  84384 non-null  int64\n",
      " 7   bin_buy  84384 non-null  int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 5.2 MB\n",
      "None\n",
      "####### Repeat ####### \n",
      " False\n",
      "####### Count ####### \n",
      " uid        84384\n",
      "gender         2\n",
      "age            7\n",
      "buy            3\n",
      "student        2\n",
      "city           4\n",
      "bin_age        2\n",
      "bin_buy        2\n",
      "dtype: int64\n",
      "####### Example ####### \n",
      "       uid  gender  age  buy  student  city  bin_age  bin_buy\n",
      "0   75862       1    2    1        1     0        1        1\n",
      "1  147011       1    4    1        1     0        0        1\n",
      "2   94599       1    0    1        1     0        0        1\n",
      "3   63085       1    4    0        1     0        0        0\n",
      "4    4048       1    4    1        1     0        0        1\n"
     ]
    }
   ],
   "source": [
    "show_df_info(filtered_user_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### nCount #######\n",
      "gender\n",
      "1    42192\n",
      "0    42192\n",
      "Name: count, dtype: int64\n",
      "age\n",
      "4    25242\n",
      "3    20932\n",
      "0    16695\n",
      "2    16263\n",
      "5     3657\n",
      "1     1563\n",
      "6       32\n",
      "Name: count, dtype: int64\n",
      "buy\n",
      "1    51060\n",
      "0    26334\n",
      "2     6990\n",
      "Name: count, dtype: int64\n",
      "student\n",
      "1    79101\n",
      "0     5283\n",
      "Name: count, dtype: int64\n",
      "city\n",
      "0    37372\n",
      "3    20593\n",
      "2    17525\n",
      "1     8894\n",
      "Name: count, dtype: int64\n",
      "bin_age\n",
      "0    45626\n",
      "1    38758\n",
      "Name: count, dtype: int64\n",
      "bin_buy\n",
      "1    58050\n",
      "0    26334\n",
      "Name: count, dtype: int64\n",
      "####### nPercent #######\n",
      "gender\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: count, dtype: float64\n",
      "age\n",
      "4    0.299133\n",
      "3    0.248057\n",
      "0    0.197846\n",
      "2    0.192726\n",
      "5    0.043338\n",
      "1    0.018522\n",
      "6    0.000379\n",
      "Name: count, dtype: float64\n",
      "buy\n",
      "1    0.605091\n",
      "0    0.312073\n",
      "2    0.082836\n",
      "Name: count, dtype: float64\n",
      "student\n",
      "1    0.937393\n",
      "0    0.062607\n",
      "Name: count, dtype: float64\n",
      "city\n",
      "0    0.442880\n",
      "3    0.244039\n",
      "2    0.207682\n",
      "1    0.105399\n",
      "Name: count, dtype: float64\n",
      "bin_age\n",
      "0    0.540695\n",
      "1    0.459305\n",
      "Name: count, dtype: float64\n",
      "bin_buy\n",
      "1    0.687927\n",
      "0    0.312073\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label_statics(filtered_user_labels, filtered_user_labels.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid1</th>\n",
       "      <th>uid2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118017</td>\n",
       "      <td>118017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118017</td>\n",
       "      <td>42978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118017</td>\n",
       "      <td>6673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118017</td>\n",
       "      <td>33244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118017</td>\n",
       "      <td>42163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061401</th>\n",
       "      <td>110307</td>\n",
       "      <td>138408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061402</th>\n",
       "      <td>110307</td>\n",
       "      <td>4433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061403</th>\n",
       "      <td>110307</td>\n",
       "      <td>33589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061404</th>\n",
       "      <td>151118</td>\n",
       "      <td>62924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29061405</th>\n",
       "      <td>62924</td>\n",
       "      <td>151118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29061406 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            uid1    uid2\n",
       "0         118017  118017\n",
       "1         118017   42978\n",
       "2         118017    6673\n",
       "3         118017   33244\n",
       "4         118017   42163\n",
       "...          ...     ...\n",
       "29061401  110307  138408\n",
       "29061402  110307    4433\n",
       "29061403  110307   33589\n",
       "29061404  151118   62924\n",
       "29061405   62924  151118\n",
       "\n",
       "[29061406 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[118017, 118017, 118017,  ..., 110307, 110307, 110307],\n",
       "        [118017,  42978,   6673,  ..., 138408,   4433,  33589]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the edges based on the remaining nodes in user_labels\n",
    "filtered_edges = user_edges[(user_edges['uid1'].isin(filtered_user_labels.index)) & (user_edges['uid2'].isin(filtered_user_labels.index))]\n",
    "filtered_edges = filtered_edges.reset_index(drop=True)\n",
    "\n",
    "# Update the edge_index variable with the filtered edges\n",
    "edge_index = torch.tensor(filtered_edges.values, dtype=torch.long).t().contiguous()\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for GNNs\n",
    "node_features = torch.tensor(user_labels.iloc[:, 1:].values, dtype=torch.float)\n",
    "edge_index = torch.tensor(user_edges.values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# node_features = torch.tensor(filtered_user_labels.iloc[:, 1:].values, dtype=torch.float)\n",
    "# edge_index = torch.tensor(filtered_edges.values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create torch-geometric data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "num_nodes = node_features.size(0)\n",
    "num_classes = 2 # Binarised gender values from the data\n",
    "num_node_features = data.num_node_features\n",
    "\n",
    "# Create masks for training, and testing\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "# 80 - 20 Train and Test data split\n",
    "num_train = int(num_nodes * 0.9)\n",
    "train_mask[:num_train] = True\n",
    "test_mask[num_train:] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "# Labels from the data (in this case: Gender Classification)\n",
    "data.y = torch.tensor(user_labels['gender'].values, dtype=torch.long)\n",
    "# data.y = torch.tensor(filtered_user_labels['gender'].values, dtype=torch.long)\n",
    "# data.y = torch.tensor(filtered_user_labels['bin_age'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[166958, 7], edge_index=[2, 29061406], train_mask=[166958], test_mask=[166958], y=[166958]) 166958 torch.Size([166958]) torch.Size([166958])\n"
     ]
    }
   ],
   "source": [
    "print(data, num_nodes, train_mask.size(), test_mask.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_aware_loss(output, data, sensitive_attr, alpha=0, beta=0, gamma=0, delta=0):\n",
    "    target = data.y[data.train_mask]\n",
    "    standard_loss = F.cross_entropy(output, target)\n",
    "\n",
    "    labels = data.y[train_mask]\n",
    "    pos_prob = torch.sigmoid(output[:, 1])\n",
    "    neg_prob = 1 - pos_prob\n",
    "    predictions = output.argmax(dim=1)\n",
    "\n",
    "    # Statistical Parity Regularization\n",
    "    sp_reg = torch.abs(pos_prob[sensitive_attr == 1].mean() - pos_prob[sensitive_attr == 0].mean())\n",
    "\n",
    "    # Calculating FPR and TPR for each group\n",
    "    fpr_group1 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 1)).float().mean()\n",
    "    fpr_group0 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 0)).float().mean()\n",
    "    tpr_group1 = ((predictions == 1) & (labels == 1) & (sensitive_attr == 1)).float().mean()\n",
    "    tpr_group0 = ((predictions == 1) & (labels == 1) & (sensitive_attr == 0)).float().mean()\n",
    "\n",
    "    # Difference in FPR and TPR between the two groups for Equalized Odds\n",
    "    fpr_diff = torch.abs(fpr_group1 - fpr_group0)\n",
    "    tpr_diff = torch.abs(tpr_group1 - tpr_group0)\n",
    "\n",
    "    # Combine FPR and TPR differences for Equalized Odds Regularization\n",
    "    equalized_odds_reg = fpr_diff + tpr_diff\n",
    "\n",
    "    # Treatment Equality Regularization\n",
    "    fp_diff = (neg_prob * (labels == 0) * (sensitive_attr == 1)).float().mean() - \\\n",
    "              (neg_prob * (labels == 0) * (sensitive_attr == 0)).float().mean()\n",
    "    fn_diff = (pos_prob * (labels == 1) * (sensitive_attr == 1)).float().mean() - \\\n",
    "              (pos_prob * (labels == 1) * (sensitive_attr == 0)).float().mean()\n",
    "    treatment_reg = torch.abs(fp_diff) + torch.abs(fn_diff)\n",
    "    # treatment_reg = torch.abs(fn_diff)\n",
    "\n",
    "    # fn_group_1 = ((predictions == 0) & (labels == 1) & (sensitive_attr == 1)).sum()\n",
    "    # fp_group_1 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 1)).sum()\n",
    "\n",
    "    # fn_group_0 = ((predictions == 0) & (labels == 1) & (sensitive_attr == 0)).sum()\n",
    "    # fp_group_0 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 0)).sum()\n",
    "    \n",
    "    # ratio_group_1 = fn_group_1 / fp_group_1 if fp_group_1 != 0 else torch.tensor(float('inf'))\n",
    "    # ratio_group_0 = fn_group_0 / fp_group_0 if fp_group_0 != 0 else torch.tensor(float('inf'))\n",
    "    # treatment_reg = torch.abs(ratio_group_1 - ratio_group_0)\n",
    "\n",
    "    # Equal Opportunity Difference Regularization\n",
    "    eod_reg = torch.abs((pos_prob * (labels == 1) * (sensitive_attr == 1)).float().mean() - \\\n",
    "                        (pos_prob * (labels == 1) * (sensitive_attr == 0)).float().mean())\n",
    "\n",
    "    # Overall Accuracy Equality Difference Regularization\n",
    "    oaed_reg = torch.abs((pos_prob * (sensitive_attr == 1)).float().mean() - \\\n",
    "                         (pos_prob * (sensitive_attr == 0)).float().mean())\n",
    "\n",
    "    penalty = alpha + beta + gamma + delta\n",
    "    \n",
    "    # Combine losses\n",
    "    combined_loss = (1-penalty)*standard_loss\n",
    "    + alpha * equalized_odds_reg\n",
    "    + beta * treatment_reg\n",
    "    + gamma * eod_reg\n",
    "    + delta * oaed_reg\n",
    "    \n",
    "    return combined_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness(label, predictions, sens_attr='bin_age', balanced=False):\n",
    "    \"\"\"\n",
    "    Calculate various fairness metrics.\n",
    "\n",
    "    Args:\n",
    "    label: Actual labels (binary).\n",
    "    predictions: Model predictions (binary).\n",
    "    sens_attr: Binary sensitive attribute for fairness evaluation.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing SPD, EOD, OAED, and TED values.\n",
    "    \"\"\"\n",
    "    if balanced is False:\n",
    "        labels = torch.tensor(user_labels[label].values, dtype=torch.long)\n",
    "        sensitive_attribute = torch.tensor(user_labels[sens_attr].values, dtype=torch.long)\n",
    "    else:\n",
    "        labels = torch.tensor(filtered_user_labels[label].values, dtype=torch.long)\n",
    "        sensitive_attribute = torch.tensor(filtered_user_labels[sens_attr].values, dtype=torch.long)\n",
    "\n",
    "    predictions = predictions.float()\n",
    "    labels = labels.float()\n",
    "    sensitive_attribute = sensitive_attribute.float()\n",
    "\n",
    "    def statistical_parity_difference():\n",
    "        prob_group_1 = predictions[sensitive_attribute == 1].mean()\n",
    "        prob_group_0 = predictions[sensitive_attribute == 0].mean()\n",
    "        return abs(prob_group_1 - prob_group_0), prob_group_0, prob_group_1\n",
    "\n",
    "    def equal_opportunity_difference():\n",
    "        tpr_group_1 = predictions[(labels == 1) & (sensitive_attribute == 1)].mean()\n",
    "        tpr_group_0 = predictions[(labels == 1) & (sensitive_attribute == 0)].mean()\n",
    "        return abs(tpr_group_1 - tpr_group_0), tpr_group_0, tpr_group_1\n",
    "\n",
    "    def overall_accuracy_equality_difference():\n",
    "        acc_group_1 = (predictions[sensitive_attribute == 1] == labels[sensitive_attribute == 1]).float().mean()\n",
    "        acc_group_0 = (predictions[sensitive_attribute == 0] == labels[sensitive_attribute == 0]).float().mean()\n",
    "        return abs(acc_group_1 - acc_group_0), acc_group_0, acc_group_1\n",
    "\n",
    "    def treatment_equality_difference():\n",
    "        fn_group_1 = ((predictions == 0) & (labels == 1) & (sensitive_attribute == 1)).sum()\n",
    "        fp_group_1 = ((predictions == 1) & (labels == 0) & (sensitive_attribute == 1)).sum()\n",
    "\n",
    "        fn_group_0 = ((predictions == 0) & (labels == 1) & (sensitive_attribute == 0)).sum()\n",
    "        fp_group_0 = ((predictions == 1) & (labels == 0) & (sensitive_attribute == 0)).sum()\n",
    "\n",
    "        ratio_group_1 = fn_group_1 / fp_group_1 if fp_group_1 != 0 else float('inf')\n",
    "        ratio_group_0 = fn_group_0 / fp_group_0 if fp_group_0 != 0 else float('inf')\n",
    "\n",
    "        return abs(ratio_group_1 - ratio_group_0), ratio_group_0, ratio_group_1, fn_group_1, fp_group_1, fn_group_0, fp_group_0\n",
    "\n",
    "    # Calculating each fairness metric\n",
    "    spd, sp_g0, sp_g1 = statistical_parity_difference()\n",
    "    eod, eod_g0, eod_g1 = equal_opportunity_difference()\n",
    "    oaed, oaed_g0, oaed_g1 = overall_accuracy_equality_difference()\n",
    "    ted, ted_g0, ted_g1, fn_group_1, fp_group_1, fn_group_0, fp_group_0 = treatment_equality_difference()\n",
    "\n",
    "    return {\n",
    "        'Statistical Parity Difference': spd,\n",
    "        'Statistical Parity Group with S=0': sp_g0,\n",
    "        'Statistical Parity Group S=1': sp_g1,\n",
    "        'Equal Opportunity Difference': eod,\n",
    "        'Equal Opportunity Group with S=0': eod_g0,\n",
    "        'Equal Opportunity Group S=1': eod_g1,\n",
    "        'Overall Accuracy Equality Difference': oaed,\n",
    "        'Overall Accuracy Group with S=0': oaed_g0,\n",
    "        'Overall Accuracy Group S=1': oaed_g1,\n",
    "        'Treatment Equality Difference': ted,\n",
    "        'Treatment Equality Group with S=0': ted_g0,\n",
    "        'Treatment Equality Group S=1': ted_g1,\n",
    "        'False Negatives Group 1': fn_group_1,\n",
    "        'False Positives Group 1': fp_group_1,\n",
    "        'False Negatives Group 0': fn_group_0,\n",
    "        'False Positives Group 0': fp_group_0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def training(model, data, optimizer, epochs, fairness=False, alpha=0, beta=0, gamma=0, delta=0):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        \n",
    "        if fairness:\n",
    "            loss = fairness_aware_loss(out[data.train_mask], data, data.x[data.train_mask, -1],\n",
    "                                       alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "            \n",
    "        else:\n",
    "            # criterion = torch.nn.CrossEntropyLoss()\n",
    "            # criterion = torch.nn.BCELoss()\n",
    "            criterion = torch.nn.NLLLoss()\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test(model, data, balanced=False):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      out = model(data.x, data.edge_index)\n",
    "\n",
    "    _, pred = model(data.x, data.edge_index).max(dim=1)\n",
    "    correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    accuracy = correct / int(data.test_mask.sum())\n",
    "    # print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Convert model outputs to binary predictions\n",
    "    predictions = out.argmax(dim=1)\n",
    "    # print(predictions[0:20])\n",
    "    # Fairness calculated for gender-classification task with bin_age as the sensitive attribute\n",
    "    fairness_metrics = calculate_fairness(label='gender', predictions=predictions, sens_attr='bin_age', balanced=balanced)\n",
    "    fairness_metrics['Accuracy'] = accuracy\n",
    "    # # Print the fairness metrics\n",
    "    # for metric, value in fairness_metrics.items():\n",
    "    #     print(f\"{metric}: {value}\")\n",
    "\n",
    "    return fairness_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metrics):\n",
    "    count = -1\n",
    "\n",
    "    for key, value in metrics.items():\n",
    "        count += 1\n",
    "        if count == 3:\n",
    "            print(f\"\\n\\n{key} : {value:.5f}\")\n",
    "            count = 0\n",
    "        else:\n",
    "            print(f\"{key} : {value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN class that takes in the data as an input for dimensions of the convolutions\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, x, edge_index):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 2) # 2 output classes for gender\n",
    "\n",
    "    def forward(self, x, edge_index, *args, **kwargs):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x = F.softmax(x, dim=1)\n",
    "        # return x\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss function and optimizer\n",
    "gcn_model = GCN(data.x, data.edge_index)\n",
    "gcn_optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.6981701850891113\n",
      "Epoch 10 | Loss: 0.5374267101287842\n",
      "Epoch 20 | Loss: 0.5077751874923706\n",
      "Epoch 30 | Loss: 0.4764851927757263\n",
      "Epoch 40 | Loss: 0.4419891834259033\n"
     ]
    }
   ],
   "source": [
    "# Train the first model: GCN, standard data, NLL loss\n",
    "training(model=gcn_model, data=data, optimizer=gcn_optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the standard GCN model with the standard NLL loss: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference : 0.04464\n",
      "Statistical Parity Group with S=0 : 0.11141\n",
      "Statistical Parity Group S=1 : 0.15606\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.05148\n",
      "Equal Opportunity Group with S=0 : 0.48409\n",
      "Equal Opportunity Group S=1 : 0.43262\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.07956\n",
      "Overall Accuracy Group with S=0 : 0.88189\n",
      "Overall Accuracy Group S=1 : 0.80233\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 3.68916\n",
      "Treatment Equality Group with S=0 : 11.48891\n",
      "Treatment Equality Group S=1 : 7.79975\n",
      "\n",
      "\n",
      "False Negatives Group 1 : 12542.00000\n",
      "False Positives Group 1 : 1608.00000\n",
      "False Negatives Group 0 : 10363.00000\n",
      "\n",
      "\n",
      "False Positives Group 0 : 902.00000\n",
      "Accuracy : 0.84505\n"
     ]
    }
   ],
   "source": [
    "# Test the first model: GCN, standard data, NLL loss\n",
    "print(\"Here are the values for the standard GCN model with the standard NLL loss: \")\n",
    "\n",
    "metrics_base_gcn_model = test(gcn_model, data)\n",
    "\n",
    "print_metrics(metrics_base_gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=gcn_model,\n",
    "    algorithm=GNNExplainer(epochs=100),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs', \n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2785, 0.2781, 0.2792,  ..., 0.2794, 0.2774, 0.2778])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.2881, 0.2857,  ..., 0.0000, 0.2824, 0.2882],\n",
      "        [0.0000, 0.2820, 0.2584,  ..., 0.0000, 0.2915, 0.2709],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.3012,  ..., 0.2736, 0.0000, 0.2844],\n",
      "        [0.0000, 0.2771, 0.2941,  ..., 0.2936, 0.0000, 0.2986],\n",
      "        [0.0000, 0.0000, 0.2736,  ..., 0.0000, 0.0000, 0.2572]])\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer(data.x, edge_index)\n",
    "print(explanation.edge_mask)\n",
    "print(explanation.node_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>buy</th>\n",
       "      <th>student</th>\n",
       "      <th>city</th>\n",
       "      <th>bin_age</th>\n",
       "      <th>bin_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166953</th>\n",
       "      <td>166953</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166954</th>\n",
       "      <td>166954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166955</th>\n",
       "      <td>166955</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166956</th>\n",
       "      <td>166956</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166957</th>\n",
       "      <td>166957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166958 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid  gender  age  buy  student  city  bin_age  bin_buy\n",
       "0            0       0    0    0        0     0        0        0\n",
       "1            1       0    1    1        1     0        1        1\n",
       "2            2       0    2    1        1     0        1        1\n",
       "3            3       0    2    1        1     1        1        1\n",
       "4            4       0    0    1        0     0        0        1\n",
       "...        ...     ...  ...  ...      ...   ...      ...      ...\n",
       "166953  166953       0    3    1        1     3        1        1\n",
       "166954  166954       0    0    1        1     3        0        1\n",
       "166955  166955       0    0    1        1     2        0        1\n",
       "166956  166956       0    4    1        1     3        0        1\n",
       "166957  166957       0    0    1        0     0        0        1\n",
       "\n",
       "[166958 rows x 8 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explanation.visualize_feature_importance(top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.5969341397285461\n",
      "Epoch 10 | Loss: 0.5347746014595032\n",
      "Epoch 20 | Loss: 0.46956467628479004\n",
      "Epoch 30 | Loss: 0.42237937450408936\n",
      "Epoch 40 | Loss: 0.3920229971408844\n"
     ]
    }
   ],
   "source": [
    "# Train the first model: GCN, standard data, cross-entropy loss\n",
    "training(model=gcn_model, data=data, optimizer=gcn_optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the standard GCN model with the standard cross-entropy loss: \n",
      "Statistical Parity Difference : 0.04279\n",
      "Statistical Parity Group with S=0 : 0.13590\n",
      "Statistical Parity Group S=1 : 0.17869\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.08792\n",
      "Equal Opportunity Group with S=0 : 0.56215\n",
      "Equal Opportunity Group S=1 : 0.47424\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.08489\n",
      "Overall Accuracy Group with S=0 : 0.89029\n",
      "Overall Accuracy Group S=1 : 0.80540\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.23409\n",
      "Treatment Equality Group with S=0 : 5.26962\n",
      "Treatment Equality Group S=1 : 5.03553\n",
      "\n",
      "\n",
      "Accuracy : 0.85326\n"
     ]
    }
   ],
   "source": [
    "# Test the first model: GCN, standard data, cross-entropy loss\n",
    "print(\"Here are the values for the standard GCN model with the standard cross-entropy loss: \")\n",
    "\n",
    "metrics_base_gcn_model = test(gcn_model, data)\n",
    "\n",
    "print_metrics(metrics_base_gcn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fair Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairnessAwareMessagePassingLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FairnessAwareMessagePassingLayer, self).__init__(aggr='mean')  \n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.a_fair = nn.Parameter(torch.rand(out_channels)) \n",
    "        self.sensitive_attr = torch.tensor(user_labels['bin_age'].values, dtype=torch.float) \n",
    "        self.bias_correction = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Add self-loops \n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "    \n",
    "    def message(self, x_j, edge_index, size):\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Compute statistical parity difference for each edge\n",
    "        group_difference = self.sensitive_attr[row] - self.sensitive_attr[col]\n",
    "        \n",
    "        # Adjust messages based on statistical parity\n",
    "        fairness_adjustment = (1 + self.bias_correction * group_difference.view(-1, 1))\n",
    "\n",
    "        return fairness_adjustment * norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_GCN(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super(custom_GCN, self).__init__()\n",
    "        self.conv1 = FairnessAwareMessagePassingLayer(data.num_node_features, 16)\n",
    "        self.conv2 = FairnessAwareMessagePassingLayer(16, 2) # 2 output classes for gender\n",
    "\n",
    "    def forward(self, x, edge_index, *args, **kwargs):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Fair Model\n",
    "\n",
    "This model is an instantiation of the `custom_GCN` using the standard cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.6914186477661133\n",
      "Epoch 10 | Loss: 0.689189076423645\n",
      "Epoch 20 | Loss: 0.6863895058631897\n",
      "Epoch 30 | Loss: 0.6826404333114624\n",
      "Epoch 40 | Loss: 0.677354633808136\n",
      "Here are the values for the CustomGNN model with the standard NLL loss: \n",
      "Statistical Parity Difference : 0.00653\n",
      "Statistical Parity Group with S=0 : 0.02462\n",
      "Statistical Parity Group S=1 : 0.03115\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.01542\n",
      "Equal Opportunity Group with S=0 : 0.11590\n",
      "Equal Opportunity Group S=1 : 0.10048\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.09149\n",
      "Overall Accuracy Group with S=0 : 0.81359\n",
      "Overall Accuracy Group S=1 : 0.72210\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 1321.38330\n",
      "Treatment Equality Group with S=0 : 887.95001\n",
      "Treatment Equality Group S=1 : 2209.33325\n",
      "\n",
      "\n",
      "False Negatives Group 1 : 19884.00000\n",
      "False Positives Group 1 : 9.00000\n",
      "False Negatives Group 0 : 17759.00000\n",
      "\n",
      "\n",
      "False Positives Group 0 : 20.00000\n",
      "Accuracy : 0.77420\n"
     ]
    }
   ],
   "source": [
    "model2 = custom_GCN(data)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model: Custom MP GNN, cross-entropy loss\n",
    "training(model=model2, data=data, optimizer=optimizer2, epochs=50)\n",
    "\n",
    "# Test the first FAIR model: CustomGNN, cross-entropy loss\n",
    "print(\"Here are the values for the CustomGNN model with the standard NLL loss: \")\n",
    "\n",
    "metrics_custom_gnn_model_1 = test(model2, data)\n",
    "\n",
    "print_metrics(metrics_custom_gnn_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "custom_GCN.forward() missing 1 required positional argument: 'edge_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaptum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IntegratedGradients\n\u001b[1;32m      6\u001b[0m ig \u001b[38;5;241m=\u001b[39m IntegratedGradients(forward_with_sigmoid)\n\u001b[0;32m----> 8\u001b[0m attributions \u001b[38;5;241m=\u001b[39m ig\u001b[38;5;241m.\u001b[39mattribute(data\u001b[38;5;241m.\u001b[39mx, target\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     12\u001b[0m node_importances \u001b[38;5;241m=\u001b[39m attributions\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attribute(\n\u001b[1;32m    287\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    288\u001b[0m         baselines\u001b[38;5;241m=\u001b[39mbaselines,\n\u001b[1;32m    289\u001b[0m         target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    290\u001b[0m         additional_forward_args\u001b[38;5;241m=\u001b[39madditional_forward_args,\n\u001b[1;32m    291\u001b[0m         n_steps\u001b[38;5;241m=\u001b[39mn_steps,\n\u001b[1;32m    292\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_func(\n\u001b[1;32m    352\u001b[0m     forward_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_func,\n\u001b[1;32m    353\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mscaled_features_tpl,\n\u001b[1;32m    354\u001b[0m     target_ind\u001b[38;5;241m=\u001b[39mexpanded_target,\n\u001b[1;32m    355\u001b[0m     additional_forward_args\u001b[38;5;241m=\u001b[39minput_additional_args,\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m _run_forward(forward_fn, inputs, target_ind, additional_forward_args)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/captum/_utils/common.py:531\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    528\u001b[0m inputs \u001b[38;5;241m=\u001b[39m _format_inputs(inputs)\n\u001b[1;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[0;32m--> 531\u001b[0m output \u001b[38;5;241m=\u001b[39m forward_func(\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39madditional_forward_args)\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m inputs\n\u001b[1;32m    535\u001b[0m )\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _select_targets(output, target)\n",
      "Cell \u001b[0;32mIn[151], line 2\u001b[0m, in \u001b[0;36mforward_with_sigmoid\u001b[0;34m(input_data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_with_sigmoid\u001b[39m(input_data):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msigmoid(model2(input_data))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: custom_GCN.forward() missing 1 required positional argument: 'edge_index'"
     ]
    }
   ],
   "source": [
    "def forward_with_sigmoid(input_data):\n",
    "    return torch.sigmoid(model2(input_data))\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "ig = IntegratedGradients(forward_with_sigmoid)\n",
    "\n",
    "attributions = ig.attribute(data.x, target=data.y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "node_importances = attributions.mean(dim=0).detach().numpy()\n",
    "\n",
    "plt.bar(np.arange(len(node_importances)), node_importances)\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Node Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m explainer2 \u001b[38;5;241m=\u001b[39m Explainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel2,\n\u001b[1;32m      3\u001b[0m     algorithm\u001b[38;5;241m=\u001b[39mGNNExplainer(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     ),\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m explanation2 \u001b[38;5;241m=\u001b[39m explainer2(data\u001b[38;5;241m.\u001b[39mx, edge_index)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(explanation2\u001b[38;5;241m.\u001b[39medge_mask)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(explanation2\u001b[38;5;241m.\u001b[39mnode_mask)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/explain/explainer.py:195\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[0;34m(self, x, edge_index, target, index, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    193\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should not be provided for the explanation \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplanation_type\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 195\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_prediction(x, edge_index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    196\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_target(prediction)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/explain/explainer.py:115\u001b[0m, in \u001b[0;36mExplainer.get_prediction\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 115\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain(training)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[145], line 8\u001b[0m, in \u001b[0;36mcustom_GCN.forward\u001b[0;34m(self, x, edge_index, *args, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 8\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index))\n\u001b[1;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlog_softmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[134], line 15\u001b[0m, in \u001b[0;36mFairnessAwareMessagePassingLayer.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m edge_index, _ \u001b[38;5;241m=\u001b[39m add_self_loops(edge_index, num_nodes\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, size\u001b[38;5;241m=\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)), x\u001b[38;5;241m=\u001b[39mx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:472\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplain:\n\u001b[1;32m    470\u001b[0m     explain_msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplain_message\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[0;32m--> 472\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplain_message(out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexplain_msg_kwargs)\n\u001b[1;32m    474\u001b[0m aggr_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_forward_pre_hooks\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:585\u001b[0m, in \u001b[0;36mMessagePassing.explain_message\u001b[0;34m(self, inputs, size_i)\u001b[0m\n\u001b[1;32m    583\u001b[0m     loop \u001b[38;5;241m=\u001b[39m edge_mask\u001b[38;5;241m.\u001b[39mnew_ones(size_i)\n\u001b[1;32m    584\u001b[0m     edge_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([edge_mask, loop], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 585\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim) \u001b[38;5;241m==\u001b[39m edge_mask\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    587\u001b[0m size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39mdim()\n\u001b[1;32m    588\u001b[0m size[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "explainer2 = Explainer(\n",
    "    model=model2,\n",
    "    algorithm=GNNExplainer(epochs=50),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs', \n",
    "    ),\n",
    ")\n",
    "\n",
    "explanation2 = explainer2(data.x, edge_index)\n",
    "print(explanation2.edge_mask)\n",
    "print(explanation2.node_mask)\n",
    "\n",
    "explanation2.visualize_feature_importance(top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the standard NLL loss: \n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Statistical Parity Difference : 0.09618\n",
      "Statistical Parity Group with S=0 : 0.00055\n",
      "Statistical Parity Group S=1 : 0.09672\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.09554\n",
      "Equal Opportunity Group with S=0 : 0.00069\n",
      "Equal Opportunity Group S=1 : 0.09622\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.12325\n",
      "Overall Accuracy Group with S=0 : 0.60343\n",
      "Overall Accuracy Group S=1 : 0.48019\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 1444.01123\n",
      "Treatment Equality Group with S=0 : 1454.23535\n",
      "Treatment Equality Group S=1 : 10.22416\n",
      "\n",
      "\n",
      "False Negatives Group 1 : 19978.00000\n",
      "False Positives Group 1 : 1954.00000\n",
      "False Negatives Group 0 : 49444.00000\n",
      "\n",
      "\n",
      "False Positives Group 0 : 34.00000\n",
      "Accuracy : 0.77192\n"
     ]
    }
   ],
   "source": [
    "print(\"Here are the values for the CustomGNN model with the standard NLL loss: \")\n",
    "\n",
    "metrics_custom_gnn_model_1 = test(model2, data)\n",
    "\n",
    "print_metrics(metrics_custom_gnn_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.6917305588722229\n",
      "Epoch 10 | Loss: 0.6893579363822937\n",
      "Epoch 20 | Loss: 0.6863116025924683\n",
      "Epoch 30 | Loss: 0.6820639371871948\n",
      "Epoch 40 | Loss: 0.6766539216041565\n"
     ]
    }
   ],
   "source": [
    "model2 = custom_GCN(data)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model: Custom MP GNN, cross-entropy loss\n",
    "training(model=model2, data=data, optimizer=optimizer2, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the standard cross-entropy loss: \n",
      "Statistical Parity Difference : 0.00867\n",
      "Statistical Parity Group with S=0 : 0.02606\n",
      "Statistical Parity Group S=1 : 0.03473\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.00996\n",
      "Equal Opportunity Group with S=0 : 0.12147\n",
      "Equal Opportunity Group S=1 : 0.11151\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.08916\n",
      "Overall Accuracy Group with S=0 : 0.81450\n",
      "Overall Accuracy Group S=1 : 0.72534\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 543.08252\n",
      "Treatment Equality Group with S=0 : 392.15555\n",
      "Treatment Equality Group S=1 : 935.23810\n",
      "\n",
      "\n",
      "Accuracy : 0.77683\n"
     ]
    }
   ],
   "source": [
    "# Test the first FAIR model: CustomGNN, cross-entropy loss\n",
    "print(\"Here are the values for the CustomGNN model with the standard cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gnn_model_1 = test(model2, data)\n",
    "\n",
    "print_metrics(metrics_custom_gnn_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Fair Model\n",
    "\n",
    "This model is an instantiation of the `custom_GCN` using the fair cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.41712942719459534\n",
      "Epoch 10 | Loss: 0.4149610698223114\n",
      "Epoch 20 | Loss: 0.4126940667629242\n",
      "Epoch 30 | Loss: 0.40997573733329773\n",
      "Epoch 40 | Loss: 0.4066038131713867\n"
     ]
    }
   ],
   "source": [
    "custom_gnn_model_2 = custom_GCN(data)\n",
    "optimizer_custom_gnn_model_2 = torch.optim.Adam(custom_gnn_model_2.parameters(), lr=0.01)\n",
    "\n",
    "fairness=True\n",
    "alpha, beta, gamma, delta = 0.1, 0.1, 0.1, 0.1\n",
    "\n",
    "# Train the model: Custom MP GNN, FAIR cross-entropy loss\n",
    "training(model=custom_gnn_model_2, \n",
    "         data=data, \n",
    "         optimizer=optimizer_custom_gnn_model_2, \n",
    "         fairness=fairness, \n",
    "         alpha=alpha, \n",
    "         beta=beta, \n",
    "         gamma=gamma, \n",
    "         delta=delta, \n",
    "         epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the FAIR standard cross-entropy loss: \n",
      "Statistical Parity Difference : 0.01379\n",
      "Statistical Parity Group with S=0 : 0.04246\n",
      "Statistical Parity Group S=1 : 0.05626\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.02047\n",
      "Equal Opportunity Group with S=0 : 0.19844\n",
      "Equal Opportunity Group S=1 : 0.17797\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.08566\n",
      "Overall Accuracy Group with S=0 : 0.83051\n",
      "Overall Accuracy Group S=1 : 0.74486\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 56.19102\n",
      "Treatment Equality Group with S=0 : 251.57812\n",
      "Treatment Equality Group S=1 : 195.38710\n",
      "\n",
      "\n",
      "Accuracy : 0.79366\n"
     ]
    }
   ],
   "source": [
    "# Test the second FAIR model: CustomGNN, FAIR cross-entropy loss\n",
    "print(\"Here are the values for the CustomGNN model with the FAIR standard cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gnn_model_2 = test(custom_gnn_model_2, data)\n",
    "\n",
    "print_metrics(metrics_custom_gnn_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third FAIR Model\n",
    "\n",
    "This model is an instantiation of the `custom_GCN` using the fair cross-entropy loss using ONLY large treatment equality penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.4166160225868225\n",
      "Epoch 10 | Loss: 0.4148714542388916\n",
      "Epoch 20 | Loss: 0.4131791591644287\n",
      "Epoch 30 | Loss: 0.41099512577056885\n",
      "Epoch 40 | Loss: 0.4082064926624298\n"
     ]
    }
   ],
   "source": [
    "custom_gnn_model_3 = custom_GCN(data)\n",
    "optimizer_custom_gnn_model_3 = torch.optim.Adam(custom_gnn_model_3.parameters(), lr=0.01)\n",
    "\n",
    "fairness=True\n",
    "alpha, beta, gamma, delta = 0, 0.4, 0, 0\n",
    "\n",
    "# Train the model: Custom MP GNN, FAIR cross-entropy loss\n",
    "training(model=custom_gnn_model_3, \n",
    "         data=data, \n",
    "         optimizer=optimizer_custom_gnn_model_3, \n",
    "         fairness=fairness, \n",
    "         alpha=alpha, \n",
    "         beta=beta, \n",
    "         gamma=gamma, \n",
    "         delta=delta, \n",
    "         epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the FAIR standard cross-entropy loss with LARGE TE penalty: \n",
      "Statistical Parity Difference : 0.01069\n",
      "Statistical Parity Group with S=0 : 0.02339\n",
      "Statistical Parity Group S=1 : 0.03409\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.00013\n",
      "Equal Opportunity Group with S=0 : 0.10997\n",
      "Equal Opportunity Group S=1 : 0.10984\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.08737\n",
      "Overall Accuracy Group with S=0 : 0.81232\n",
      "Overall Accuracy Group S=1 : 0.72495\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 827.11365\n",
      "Treatment Equality Group with S=0 : 812.63635\n",
      "Treatment Equality Group S=1 : 1639.75000\n",
      "\n",
      "\n",
      "Accuracy : 0.77486\n"
     ]
    }
   ],
   "source": [
    "# Test the third FAIR model: CustomGNN, FAIR cross-entropy loss with LARGE TE penalty\n",
    "print(\"Here are the values for the CustomGNN model with the FAIR standard cross-entropy loss with LARGE TE penalty: \")\n",
    "\n",
    "metrics_custom_gnn_model_3 = test(custom_gnn_model_3, data)\n",
    "\n",
    "print_metrics(metrics_custom_gnn_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Fair Model\n",
    "\n",
    "This model is going to use a different custom_GCN model, normal CE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomCELoss(nn.Module):\n",
    "#     def __init__(self, sensitive_attr_weight=0.0):\n",
    "#         super(CustomCELoss, self).__init__()\n",
    "#         self.sensitive_attr_weight = sensitive_attr_weight\n",
    "#         self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#     def forward(self, input, target, sensitive_attr):\n",
    "#         ce_loss = self.ce_loss(input, target)\n",
    "#         reg_loss = self.sensitive_attr_weight * torch.mean(torch.abs(sensitive_attr))\n",
    "#         total_loss = ce_loss + reg_loss\n",
    "#         return total_loss\n",
    "    \n",
    "class CustomCELoss(nn.Module):\n",
    "    def __init__(self, sensitive_attr_weight=0.0):\n",
    "        super(CustomCELoss, self).__init__()\n",
    "        self.sensitive_attr_weight = sensitive_attr_weight\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input, target, sensitive_attr):\n",
    "        ce_loss = self.ce_loss(input, target)\n",
    "        reg_loss = self.sensitive_attr_weight * torch.mean(torch.abs(sensitive_attr - 0.5))\n",
    "        total_loss = ce_loss + reg_loss\n",
    "        return total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_attribute = torch.tensor(user_labels['bin_age'].values, dtype=torch.long)\n",
    "sensitive_attribute = sensitive_attribute.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1.,  ..., 1., 1., 0.])\n",
      "tensor([0., 1., 1.,  ..., 1., 0., 0.])\n",
      "0.5527379722384439\n"
     ]
    }
   ],
   "source": [
    "print(sensitive_attribute[data.train_mask])\n",
    "\n",
    "print(data.x[data.train_mask, -1])\n",
    "\n",
    "# calculate percentage of equal entries in the sensitive attribute and data.x\n",
    "print(sensitive_attribute[data.train_mask].eq(data.x[data.train_mask, -1]).sum().item() / int(data.train_mask.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with customCE loss\n",
    "def training_customCE(model, data, optimizer, epochs, sensitive_attr_weight):\n",
    "    criterion = CustomCELoss(sensitive_attr_weight=sensitive_attr_weight)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        # loss = criterion(out[data.train_mask], data.y[data.train_mask], data.x[data.train_mask, -1])\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask], sensitive_attribute[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.6968374848365784\n",
      "Epoch 10 | Loss: 0.6945965886116028\n",
      "Epoch 20 | Loss: 0.6928642988204956\n",
      "Epoch 30 | Loss: 0.6906540989875793\n",
      "Epoch 40 | Loss: 0.6872914433479309\n"
     ]
    }
   ],
   "source": [
    "custom_gnn_model_4 = custom_GCN(data)\n",
    "optimizer_custom_gnn_model_4 = torch.optim.Adam(custom_gnn_model_4.parameters(), lr=0.01)\n",
    "\n",
    "sensitive_attr_weight = 0.01\n",
    "\n",
    "# Train the model: Custom MP GNN, custom cross-entropy loss\n",
    "training_customCE(model=custom_gnn_model_4, \n",
    "                  data=data, \n",
    "                  optimizer=optimizer_custom_gnn_model_4, \n",
    "                  epochs=50, \n",
    "                  sensitive_attr_weight=sensitive_attr_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the custom cross-entropy loss: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Parity Difference : 0.00362\n",
      "Statistical Parity Group with S=0 : 0.00685\n",
      "Statistical Parity Group S=1 : 0.01046\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.00152\n",
      "Equal Opportunity Group with S=0 : 0.03236\n",
      "Equal Opportunity Group S=1 : 0.03388\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.09451\n",
      "Overall Accuracy Group with S=0 : 0.79617\n",
      "Overall Accuracy Group S=1 : 0.70166\n",
      "\n",
      "\n",
      "Treatment Equality Difference : inf\n",
      "Treatment Equality Group with S=0 : 6479.00000\n",
      "Treatment Equality Group S=1 : inf\n",
      "\n",
      "\n",
      "Accuracy : 0.75545\n"
     ]
    }
   ],
   "source": [
    "# Test the fourth FAIR model: CustomGNN, custom cross-entropy loss\n",
    "print(\"Here are the values for the CustomGNN model with the custom cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gnn_model_4 = test(custom_gnn_model_4, data)\n",
    "\n",
    "print_metrics(metrics_custom_gnn_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention-based Message Passing\n",
    "\n",
    "In this section, the models are trained using a custom attention-based message passing model.  \n",
    "This custom attention should take the sensitive attribute into consideration when calculating the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline GAT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT class that takes in the data as an input for dimensions of the convolutions\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(data.num_node_features, 16)\n",
    "        self.conv2 = GATConv(16, 2) # 2 output classes for gender\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss function and optimizer\n",
    "gat_model = GAT(data)\n",
    "gat_optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 1.243209719657898\n",
      "Epoch 10 | Loss: 0.6583862900733948\n",
      "Epoch 20 | Loss: 0.5705628991127014\n",
      "Epoch 30 | Loss: 0.5451962947845459\n",
      "Epoch 40 | Loss: 0.5258474946022034\n"
     ]
    }
   ],
   "source": [
    "training(model=gat_model, data=data, optimizer=gat_optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the standard GAT model with the standard cross-entropy loss: \n",
      "Statistical Parity Difference : 0.00537\n",
      "Statistical Parity Group with S=0 : 0.00704\n",
      "Statistical Parity Group S=1 : 0.01241\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.00406\n",
      "Equal Opportunity Group with S=0 : 0.02932\n",
      "Equal Opportunity Group S=1 : 0.03339\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.09529\n",
      "Overall Accuracy Group with S=0 : 0.79471\n",
      "Overall Accuracy Group S=1 : 0.69941\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 95.33382\n",
      "Treatment Equality Group with S=0 : 237.78049\n",
      "Treatment Equality Group S=1 : 142.44667\n",
      "\n",
      "\n",
      "Accuracy : 0.75287\n"
     ]
    }
   ],
   "source": [
    "# Test the first model: GAT, standard data, cross-entropy loss\n",
    "print(\"Here are the values for the standard GAT model with the standard cross-entropy loss: \")\n",
    "\n",
    "metrics_base_gat_model = test(gat_model, data)\n",
    "\n",
    "print_metrics(metrics_base_gat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Parity Difference : 0.00372\n",
    "Statistical Parity Group with S=0 : 0.00472\n",
    "Statistical Parity Group S=1 : 0.00844\n",
    "\n",
    "\n",
    "Equal Opportunity Difference : 0.00493\n",
    "Equal Opportunity Group with S=0 : 0.02235\n",
    "Equal Opportunity Group S=1 : 0.02728\n",
    "\n",
    "\n",
    "Overall Accuracy Equality Difference : 0.09448\n",
    "Overall Accuracy Group with S=0 : 0.79409\n",
    "Overall Accuracy Group S=1 : 0.69961\n",
    "\n",
    "\n",
    "Treatment Equality Difference : 1864.00000\n",
    "Treatment Equality Group with S=0 : 19638.00000\n",
    "Treatment Equality Group S=1 : 21502.00000\n",
    "\n",
    "\n",
    "Accuracy : 0.75335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FairMP GAT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class Attention_FairMessagePassing(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Attention_FairMessagePassing, self).__init__(aggr='mean')\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.att = nn.Linear(out_channels, 1)\n",
    "        self.sensitive_attr = torch.tensor(user_labels['bin_age'].values, dtype=torch.float)\n",
    "        self.bias_correction = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Add self-loops\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.lin(x)\n",
    "        x = self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # Calculate attention weights\n",
    "        alpha = self.att(torch.abs(x_i - x_j))\n",
    "        alpha = torch.exp(alpha) / (torch.exp(alpha).sum(dim=1, keepdim=True) + self.bias_correction)\n",
    "\n",
    "        # Apply attention weights to messages\n",
    "        return x_j * alpha\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT class that takes in the data as an input for dimensions of the convolutions\n",
    "class CustomGAT(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super(CustomGAT, self).__init__()\n",
    "        self.conv1 = Attention_FairMessagePassing(data.num_node_features, 16)\n",
    "        self.conv2 = Attention_FairMessagePassing(16, 2) # 2 output classes for gender\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Fair GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss function and optimizer\n",
    "custom_gat_model = CustomGAT(data)\n",
    "custom_gat_optimizer = torch.optim.Adam(custom_gat_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.7300261855125427\n",
      "Epoch 10 | Loss: 0.5912700891494751\n",
      "Epoch 20 | Loss: 0.5659604668617249\n",
      "Epoch 30 | Loss: 0.5476182103157043\n",
      "Epoch 40 | Loss: 0.5287064909934998\n"
     ]
    }
   ],
   "source": [
    "training(model=custom_gat_model, data=data, optimizer=custom_gat_optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGAT model with the standard cross-entropy loss: \n",
      "Statistical Parity Difference : 0.00372\n",
      "Statistical Parity Group with S=0 : 0.00472\n",
      "Statistical Parity Group S=1 : 0.00844\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.00493\n",
      "Equal Opportunity Group with S=0 : 0.02235\n",
      "Equal Opportunity Group S=1 : 0.02728\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.09448\n",
      "Overall Accuracy Group with S=0 : 0.79409\n",
      "Overall Accuracy Group S=1 : 0.69961\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 1864.00000\n",
      "Treatment Equality Group with S=0 : 19638.00000\n",
      "Treatment Equality Group S=1 : 21502.00000\n",
      "\n",
      "\n",
      "Accuracy : 0.75335\n"
     ]
    }
   ],
   "source": [
    "# Test the first model: CustomGAT, standard data, cross-entropy loss\n",
    "print(\"Here are the values for the CustomGAT model with the standard cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gat_model = test(custom_gat_model, data)\n",
    "\n",
    "print_metrics(metrics_custom_gat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Fair GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss function and optimizer\n",
    "custom_gat_model_2 = CustomGAT(data)\n",
    "custom_gat_optimizer_2 = torch.optim.Adam(custom_gat_model_2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.7302701473236084\n",
      "Epoch 10 | Loss: 0.5995766520500183\n",
      "Epoch 20 | Loss: 0.512322187423706\n",
      "Epoch 30 | Loss: 0.48978760838508606\n",
      "Epoch 40 | Loss: 0.46570953726768494\n"
     ]
    }
   ],
   "source": [
    "training(model=custom_gat_model_2, data=data, optimizer=custom_gat_optimizer_2, fairness=True, beta=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGAT model with the FAIR cross-entropy loss: \n",
      "Statistical Parity Difference : 0.01193\n",
      "Statistical Parity Group with S=0 : 0.02863\n",
      "Statistical Parity Group S=1 : 0.04057\n",
      "\n",
      "\n",
      "Equal Opportunity Difference : 0.00700\n",
      "Equal Opportunity Group with S=0 : 0.13417\n",
      "Equal Opportunity Group S=1 : 0.12717\n",
      "\n",
      "\n",
      "Overall Accuracy Equality Difference : 0.08810\n",
      "Overall Accuracy Group with S=0 : 0.81727\n",
      "Overall Accuracy Group S=1 : 0.72917\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 275.64874\n",
      "Treatment Equality Group with S=0 : 483.11111\n",
      "Treatment Equality Group S=1 : 207.46237\n",
      "\n",
      "\n",
      "Accuracy : 0.77851\n"
     ]
    }
   ],
   "source": [
    "# Test the second model: CustomGAT, FAIR cross-entropy loss\n",
    "print(\"Here are the values for the CustomGAT model with the FAIR cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gat_model_2 = test(custom_gat_model_2, data)\n",
    "\n",
    "print_metrics(metrics_custom_gat_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
