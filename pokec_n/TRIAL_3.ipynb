{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Imports\n",
    "# ------------------------------------------------------------------\n",
    "# Basic data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Graph data processing libraries\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "# Libraries for (G)NNs\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import torch.nn as nn\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Helper functions\n",
    "# ------------------------------------------------------------------\n",
    "def show_df_info(df):\n",
    "    print(df.info())\n",
    "    print('####### Repeat ####### \\n', df.duplicated().any())\n",
    "    print('####### Count ####### \\n', df.nunique())\n",
    "    print('####### Example ####### \\n',df.head())\n",
    "\n",
    "def label_statics(label_df, label_list):\n",
    "    print(\"####### nCount #######\")\n",
    "    for label in label_list:\n",
    "        print(label_df[label].value_counts())\n",
    "    print(\"####### nPercent #######\")\n",
    "    for label in label_list:\n",
    "        print(label_df[label].value_counts()/label_df.shape[0])\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Data stuff\n",
    "# ------------------------------------------------------------------\n",
    "base_path = os.getcwd()\n",
    "input_ali_data_path = base_path\n",
    "\n",
    "# Load the data files\n",
    "user_labels_path = os.path.join(input_ali_data_path, \"region_job_2.csv\")\n",
    "user_edges_path = os.path.join(input_ali_data_path, \"region_job_relationship_2.csv\")\n",
    "\n",
    "# Create dataframes to store the information from the .csv files\n",
    "user_labels = pd.read_csv(user_labels_path)\n",
    "user_edges = pd.read_csv(user_edges_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid1</th>\n",
       "      <th>uid2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>122795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1482970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176</td>\n",
       "      <td>4454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745</td>\n",
       "      <td>21766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729124</th>\n",
       "      <td>1632683</td>\n",
       "      <td>1631897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729125</th>\n",
       "      <td>1632705</td>\n",
       "      <td>1631675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729126</th>\n",
       "      <td>1632707</td>\n",
       "      <td>1631675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729127</th>\n",
       "      <td>1632724</td>\n",
       "      <td>1631566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729128</th>\n",
       "      <td>1632773</td>\n",
       "      <td>1632741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>729129 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid1     uid2\n",
       "0            14   122795\n",
       "1            14  1482970\n",
       "2           176     4461\n",
       "3           176     4454\n",
       "4           745    21766\n",
       "...         ...      ...\n",
       "729124  1632683  1631897\n",
       "729125  1632705  1631675\n",
       "729126  1632707  1631675\n",
       "729127  1632724  1631566\n",
       "729128  1632773  1632741\n",
       "\n",
       "[729129 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>public</th>\n",
       "      <th>completion_percentage</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>AGE</th>\n",
       "      <th>I_am_working_in_field</th>\n",
       "      <th>spoken_languages_indicator</th>\n",
       "      <th>anglicky</th>\n",
       "      <th>nemecky</th>\n",
       "      <th>...</th>\n",
       "      <th>rozpravky</th>\n",
       "      <th>odbornu literaturu</th>\n",
       "      <th>psychologicku literaturu</th>\n",
       "      <th>literaturu pre rozvoj osobnosti</th>\n",
       "      <th>cestopisy</th>\n",
       "      <th>literaturu faktu</th>\n",
       "      <th>zivotopisne a pamate</th>\n",
       "      <th>poeziu</th>\n",
       "      <th>pocitacovu literaturu</th>\n",
       "      <th>filozoficku literaturu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179648</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>917506</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>917511</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655367</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1310729</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66564</th>\n",
       "      <td>262137</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66565</th>\n",
       "      <td>1179642</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66566</th>\n",
       "      <td>262139</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66567</th>\n",
       "      <td>917500</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66568</th>\n",
       "      <td>1048573</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66569 rows Ã— 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  public  completion_percentage  gender  region   AGE  \\\n",
       "0      1179648       0                     71     1.0       0   0.0   \n",
       "1       917506       1                     45     1.0       0   0.0   \n",
       "2       917511       1                     12     0.0       0  30.0   \n",
       "3       655367       0                     12     0.0       0  21.0   \n",
       "4      1310729       1                     47     0.0       1  38.0   \n",
       "...        ...     ...                    ...     ...     ...   ...   \n",
       "66564   262137       1                     64     0.0       1  25.0   \n",
       "66565  1179642       1                     71     1.0       1  20.0   \n",
       "66566   262139       0                     62     0.0       1   0.0   \n",
       "66567   917500       0                     71     1.0       0  21.0   \n",
       "66568  1048573       0                     57     1.0       0  16.0   \n",
       "\n",
       "       I_am_working_in_field  spoken_languages_indicator  anglicky  nemecky  \\\n",
       "0                          1                           0         0        0   \n",
       "1                         -1                           1         1        0   \n",
       "2                         -1                           0         0        0   \n",
       "3                         -1                           0         0        0   \n",
       "4                         -1                           1         0        0   \n",
       "...                      ...                         ...       ...      ...   \n",
       "66564                     -1                           1         1        0   \n",
       "66565                     -1                           1         1        0   \n",
       "66566                     -1                           1         1        0   \n",
       "66567                     -1                           1         0        0   \n",
       "66568                      0                           1         1        0   \n",
       "\n",
       "       ...  rozpravky  odbornu literaturu  psychologicku literaturu  \\\n",
       "0      ...          0                   0                         0   \n",
       "1      ...          0                   0                         0   \n",
       "2      ...          0                   0                         0   \n",
       "3      ...          0                   0                         0   \n",
       "4      ...          0                   0                         0   \n",
       "...    ...        ...                 ...                       ...   \n",
       "66564  ...          0                   1                         0   \n",
       "66565  ...          0                   0                         0   \n",
       "66566  ...          0                   0                         0   \n",
       "66567  ...          0                   0                         1   \n",
       "66568  ...          0                   0                         0   \n",
       "\n",
       "       literaturu pre rozvoj osobnosti  cestopisy  literaturu faktu  \\\n",
       "0                                    1          1                 0   \n",
       "1                                    0          0                 0   \n",
       "2                                    0          0                 0   \n",
       "3                                    0          0                 0   \n",
       "4                                    0          0                 0   \n",
       "...                                ...        ...               ...   \n",
       "66564                                0          0                 1   \n",
       "66565                                0          0                 0   \n",
       "66566                                0          0                 0   \n",
       "66567                                0          0                 1   \n",
       "66568                                0          0                 0   \n",
       "\n",
       "       zivotopisne a pamate  poeziu  pocitacovu literaturu  \\\n",
       "0                         1       0                      0   \n",
       "1                         0       0                      0   \n",
       "2                         0       0                      0   \n",
       "3                         0       0                      0   \n",
       "4                         0       0                      0   \n",
       "...                     ...     ...                    ...   \n",
       "66564                     0       0                      0   \n",
       "66565                     0       0                      0   \n",
       "66566                     0       0                      0   \n",
       "66567                     0       0                      0   \n",
       "66568                     0       0                      0   \n",
       "\n",
       "       filozoficku literaturu  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "66564                       0  \n",
       "66565                       0  \n",
       "66566                       0  \n",
       "66567                       0  \n",
       "66568                       0  \n",
       "\n",
       "[66569 rows x 268 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66569 entries, 0 to 66568\n",
      "Columns: 268 entries, user_id to filozoficku literaturu\n",
      "dtypes: float64(2), int64(266)\n",
      "memory usage: 136.1 MB\n",
      "None\n",
      "####### Repeat ####### \n",
      " False\n",
      "####### Count ####### \n",
      " user_id                   66569\n",
      "public                        2\n",
      "completion_percentage        52\n",
      "gender                        2\n",
      "region                        2\n",
      "                          ...  \n",
      "literaturu faktu              2\n",
      "zivotopisne a pamate          2\n",
      "poeziu                        2\n",
      "pocitacovu literaturu         2\n",
      "filozoficku literaturu        2\n",
      "Length: 268, dtype: int64\n",
      "####### Example ####### \n",
      "    user_id  public  completion_percentage  gender  region   AGE  \\\n",
      "0  1179648       0                     71     1.0       0   0.0   \n",
      "1   917506       1                     45     1.0       0   0.0   \n",
      "2   917511       1                     12     0.0       0  30.0   \n",
      "3   655367       0                     12     0.0       0  21.0   \n",
      "4  1310729       1                     47     0.0       1  38.0   \n",
      "\n",
      "   I_am_working_in_field  spoken_languages_indicator  anglicky  nemecky  ...  \\\n",
      "0                      1                           0         0        0  ...   \n",
      "1                     -1                           1         1        0  ...   \n",
      "2                     -1                           0         0        0  ...   \n",
      "3                     -1                           0         0        0  ...   \n",
      "4                     -1                           1         0        0  ...   \n",
      "\n",
      "   rozpravky  odbornu literaturu  psychologicku literaturu  \\\n",
      "0          0                   0                         0   \n",
      "1          0                   0                         0   \n",
      "2          0                   0                         0   \n",
      "3          0                   0                         0   \n",
      "4          0                   0                         0   \n",
      "\n",
      "   literaturu pre rozvoj osobnosti  cestopisy  literaturu faktu  \\\n",
      "0                                1          1                 0   \n",
      "1                                0          0                 0   \n",
      "2                                0          0                 0   \n",
      "3                                0          0                 0   \n",
      "4                                0          0                 0   \n",
      "\n",
      "   zivotopisne a pamate  poeziu  pocitacovu literaturu  filozoficku literaturu  \n",
      "0                     1       0                      0                       0  \n",
      "1                     0       0                      0                       0  \n",
      "2                     0       0                      0                       0  \n",
      "3                     0       0                      0                       0  \n",
      "4                     0       0                      0                       0  \n",
      "\n",
      "[5 rows x 268 columns]\n"
     ]
    }
   ],
   "source": [
    "show_df_info(user_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### nCount #######\n",
      "0    47338\n",
      "1    19231\n",
      "Name: region, dtype: int64\n",
      "-1    57772\n",
      " 0     4510\n",
      " 1     1789\n",
      " 2     1353\n",
      " 3     1145\n",
      "Name: I_am_working_in_field, dtype: int64\n",
      "####### nPercent #######\n",
      "0    0.711112\n",
      "1    0.288888\n",
      "Name: region, dtype: float64\n",
      "-1    0.867851\n",
      " 0    0.067749\n",
      " 1    0.026874\n",
      " 2    0.020325\n",
      " 3    0.017200\n",
      "Name: I_am_working_in_field, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label_statics(user_labels, ['region', 'I_am_working_in_field'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           uid1     uid2\n",
       " 0            14   122795\n",
       " 1            14  1482970\n",
       " 2           176     4461\n",
       " 3           176     4454\n",
       " 4           745    21766\n",
       " ...         ...      ...\n",
       " 729124  1632683  1631897\n",
       " 729125  1632705  1631675\n",
       " 729126  1632707  1631675\n",
       " 729127  1632724  1631566\n",
       " 729128  1632773  1632741\n",
       " \n",
       " [729129 rows x 2 columns],\n",
       " (729129, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_edges = user_edges[user_edges['uid1'].isin(user_labels['user_id']) & user_edges['uid2'].isin(user_labels['user_id'])]\n",
    "user_edges, user_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>public</th>\n",
       "      <th>completion_percentage</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>AGE</th>\n",
       "      <th>spoken_languages_indicator</th>\n",
       "      <th>anglicky</th>\n",
       "      <th>nemecky</th>\n",
       "      <th>rusky</th>\n",
       "      <th>...</th>\n",
       "      <th>rozpravky</th>\n",
       "      <th>odbornu literaturu</th>\n",
       "      <th>psychologicku literaturu</th>\n",
       "      <th>literaturu pre rozvoj osobnosti</th>\n",
       "      <th>cestopisy</th>\n",
       "      <th>literaturu faktu</th>\n",
       "      <th>zivotopisne a pamate</th>\n",
       "      <th>poeziu</th>\n",
       "      <th>pocitacovu literaturu</th>\n",
       "      <th>filozoficku literaturu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1179648</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>917506</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>917511</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>655367</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1310729</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66564</th>\n",
       "      <td>262137</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66565</th>\n",
       "      <td>1179642</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66566</th>\n",
       "      <td>262139</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66567</th>\n",
       "      <td>917500</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66568</th>\n",
       "      <td>1048573</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66569 rows Ã— 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  public  completion_percentage  gender  region   AGE  \\\n",
       "0      1179648       0                     71     1.0       0   0.0   \n",
       "1       917506       1                     45     1.0       0   0.0   \n",
       "2       917511       1                     12     0.0       0  30.0   \n",
       "3       655367       0                     12     0.0       0  21.0   \n",
       "4      1310729       1                     47     0.0       1  38.0   \n",
       "...        ...     ...                    ...     ...     ...   ...   \n",
       "66564   262137       1                     64     0.0       1  25.0   \n",
       "66565  1179642       1                     71     1.0       1  20.0   \n",
       "66566   262139       0                     62     0.0       1   0.0   \n",
       "66567   917500       0                     71     1.0       0  21.0   \n",
       "66568  1048573       0                     57     1.0       0  16.0   \n",
       "\n",
       "       spoken_languages_indicator  anglicky  nemecky  rusky  ...  rozpravky  \\\n",
       "0                               0         0        0      0  ...          0   \n",
       "1                               1         1        0      0  ...          0   \n",
       "2                               0         0        0      0  ...          0   \n",
       "3                               0         0        0      0  ...          0   \n",
       "4                               1         0        0      0  ...          0   \n",
       "...                           ...       ...      ...    ...  ...        ...   \n",
       "66564                           1         1        0      0  ...          0   \n",
       "66565                           1         1        0      0  ...          0   \n",
       "66566                           1         1        0      0  ...          0   \n",
       "66567                           1         0        0      0  ...          0   \n",
       "66568                           1         1        0      0  ...          0   \n",
       "\n",
       "       odbornu literaturu  psychologicku literaturu  \\\n",
       "0                       0                         0   \n",
       "1                       0                         0   \n",
       "2                       0                         0   \n",
       "3                       0                         0   \n",
       "4                       0                         0   \n",
       "...                   ...                       ...   \n",
       "66564                   1                         0   \n",
       "66565                   0                         0   \n",
       "66566                   0                         0   \n",
       "66567                   0                         1   \n",
       "66568                   0                         0   \n",
       "\n",
       "       literaturu pre rozvoj osobnosti  cestopisy  literaturu faktu  \\\n",
       "0                                    1          1                 0   \n",
       "1                                    0          0                 0   \n",
       "2                                    0          0                 0   \n",
       "3                                    0          0                 0   \n",
       "4                                    0          0                 0   \n",
       "...                                ...        ...               ...   \n",
       "66564                                0          0                 1   \n",
       "66565                                0          0                 0   \n",
       "66566                                0          0                 0   \n",
       "66567                                0          0                 1   \n",
       "66568                                0          0                 0   \n",
       "\n",
       "       zivotopisne a pamate  poeziu  pocitacovu literaturu  \\\n",
       "0                         1       0                      0   \n",
       "1                         0       0                      0   \n",
       "2                         0       0                      0   \n",
       "3                         0       0                      0   \n",
       "4                         0       0                      0   \n",
       "...                     ...     ...                    ...   \n",
       "66564                     0       0                      0   \n",
       "66565                     0       0                      0   \n",
       "66566                     0       0                      0   \n",
       "66567                     0       0                      0   \n",
       "66568                     0       0                      0   \n",
       "\n",
       "       filozoficku literaturu  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "66564                       0  \n",
       "66565                       0  \n",
       "66566                       0  \n",
       "66567                       0  \n",
       "66568                       0  \n",
       "\n",
       "[66569 rows x 267 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_labels_train = user_labels\n",
    "user_labels_train = user_labels_train.drop(columns=['I_am_working_in_field'])\n",
    "user_labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract node features from user_labels dataframe\n",
    "node_features = user_labels_train.iloc[:, 1:] # Replace 'attribute1', 'attribute2', ... with the actual attribute columns you want to use\n",
    "node_features = torch.tensor(node_features.values, dtype=torch.float)\n",
    "\n",
    "# Extract edges from user_edges dataframe\n",
    "edges = user_edges[['uid1', 'uid2']]\n",
    "edges['uid1'] = edges['uid1'].map(dict(zip(user_labels['user_id'], range(len(user_labels)))))\n",
    "edges['uid2'] = edges['uid2'].map(dict(zip(user_labels['user_id'], range(len(user_labels)))))\n",
    "\n",
    "# Convert edges dataframe to tensor\n",
    "edges_tensor = torch.tensor(edges.values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create edge_index tensor\n",
    "edge_index = edges_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labels['I_am_working_in_field'] = user_labels['I_am_working_in_field'].map({-1: 0, 0: 1, 1: 1, 2: 1, 3: 1, 4: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for GNNs\n",
    "# node_features = torch.tensor(user_labels.iloc[:, 1:].values, dtype=torch.float)\n",
    "# edge_index = torch.tensor(user_edges.values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# node_features = torch.tensor(filtered_user_labels.iloc[:, 1:].values, dtype=torch.float)\n",
    "# edge_index = torch.tensor(filtered_edges.values, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create torch-geometric data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "num_nodes = node_features.size(0)\n",
    "num_classes = 2 \n",
    "num_node_features = data.num_node_features\n",
    "\n",
    "# Create masks for training, and testing\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "# 80 - 20 Train and Test data split\n",
    "num_train = int(num_nodes * 0.8)\n",
    "train_mask[:num_train] = True\n",
    "test_mask[num_train:] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "# Labels from the data (in this case: Job Classification)\n",
    "data.y = torch.tensor(user_labels['I_am_working_in_field'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### nCount #######\n",
      "0    47338\n",
      "1    19231\n",
      "Name: region, dtype: int64\n",
      "0    57772\n",
      "1     8797\n",
      "Name: I_am_working_in_field, dtype: int64\n",
      "####### nPercent #######\n",
      "0    0.711112\n",
      "1    0.288888\n",
      "Name: region, dtype: float64\n",
      "0    0.867851\n",
      "1    0.132149\n",
      "Name: I_am_working_in_field, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label_statics(user_labels, ['region', 'I_am_working_in_field'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([66569, 266]), torch.Size([2, 729129]), torch.Size([66569]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.shape, edge_index.shape, data.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[66569, 266], edge_index=[2, 729129], train_mask=[66569], test_mask=[66569], y=[66569]) 66569 torch.Size([66569]) torch.Size([66569])\n"
     ]
    }
   ],
   "source": [
    "print(data, num_nodes, train_mask.size(), test_mask.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([66569, 266]), torch.Size([66569]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape, data.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_aware_loss(output, data, sensitive_attr, alpha=0, beta=0, gamma=0, delta=0):\n",
    "    target = data.y[data.train_mask]\n",
    "    standard_loss = F.cross_entropy(output, target)\n",
    "\n",
    "    labels = data.y[train_mask]\n",
    "    pos_prob = torch.sigmoid(output[:, 1])\n",
    "    neg_prob = 1 - pos_prob\n",
    "    predictions = output.argmax(dim=1)\n",
    "\n",
    "    # Statistical Parity Regularization\n",
    "    sp_reg = torch.abs(pos_prob[sensitive_attr == 1].mean() - pos_prob[sensitive_attr == 0].mean())\n",
    "\n",
    "    # Calculating FPR and TPR for each group\n",
    "    fpr_group1 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 1)).float().mean()\n",
    "    fpr_group0 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 0)).float().mean()\n",
    "    tpr_group1 = ((predictions == 1) & (labels == 1) & (sensitive_attr == 1)).float().mean()\n",
    "    tpr_group0 = ((predictions == 1) & (labels == 1) & (sensitive_attr == 0)).float().mean()\n",
    "\n",
    "    # Difference in FPR and TPR between the two groups for Equalized Odds\n",
    "    fpr_diff = torch.abs(fpr_group1 - fpr_group0)\n",
    "    tpr_diff = torch.abs(tpr_group1 - tpr_group0)\n",
    "\n",
    "    # Combine FPR and TPR differences for Equalized Odds Regularization\n",
    "    equalized_odds_reg = fpr_diff + tpr_diff\n",
    "\n",
    "    # Treatment Equality Regularization\n",
    "    fp_diff = (neg_prob * (labels == 0) * (sensitive_attr == 1)).float().mean() - \\\n",
    "              (neg_prob * (labels == 0) * (sensitive_attr == 0)).float().mean()\n",
    "    fn_diff = (pos_prob * (labels == 1) * (sensitive_attr == 1)).float().mean() - \\\n",
    "              (pos_prob * (labels == 1) * (sensitive_attr == 0)).float().mean()\n",
    "    treatment_reg = torch.abs(fp_diff) + torch.abs(fn_diff)\n",
    "    # treatment_reg = torch.abs(fn_diff)\n",
    "\n",
    "    # fn_group_1 = ((predictions == 0) & (labels == 1) & (sensitive_attr == 1)).sum()\n",
    "    # fp_group_1 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 1)).sum()\n",
    "\n",
    "    # fn_group_0 = ((predictions == 0) & (labels == 1) & (sensitive_attr == 0)).sum()\n",
    "    # fp_group_0 = ((predictions == 1) & (labels == 0) & (sensitive_attr == 0)).sum()\n",
    "    \n",
    "    # ratio_group_1 = fn_group_1 / fp_group_1 if fp_group_1 != 0 else torch.tensor(float('inf'))\n",
    "    # ratio_group_0 = fn_group_0 / fp_group_0 if fp_group_0 != 0 else torch.tensor(float('inf'))\n",
    "    # treatment_reg = torch.abs(ratio_group_1 - ratio_group_0)\n",
    "\n",
    "    # Equal Opportunity Difference Regularization\n",
    "    eod_reg = torch.abs((pos_prob * (labels == 1) * (sensitive_attr == 1)).float().mean() - \\\n",
    "                        (pos_prob * (labels == 1) * (sensitive_attr == 0)).float().mean())\n",
    "\n",
    "    # Overall Accuracy Equality Difference Regularization\n",
    "    oaed_reg = torch.abs((pos_prob * (sensitive_attr == 1)).float().mean() - \\\n",
    "                         (pos_prob * (sensitive_attr == 0)).float().mean())\n",
    "\n",
    "    penalty = alpha + beta + gamma + delta\n",
    "    \n",
    "    # Combine losses\n",
    "    combined_loss = (1-penalty)*standard_loss\n",
    "    + alpha * equalized_odds_reg\n",
    "    + beta * treatment_reg\n",
    "    + gamma * eod_reg\n",
    "    + delta * oaed_reg\n",
    "    \n",
    "    return combined_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness(label, predictions, sens_attr='region', balanced=False):\n",
    "    \"\"\"\n",
    "    Calculate various fairness metrics.\n",
    "\n",
    "    Args:\n",
    "    label: Actual labels (binary).\n",
    "    predictions: Model predictions (binary).\n",
    "    sens_attr: Binary sensitive attribute for fairness evaluation.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing SPD, EOD, OAED, and TED values.\n",
    "    \"\"\"\n",
    "    if balanced is False:\n",
    "        labels = torch.tensor(user_labels[label].values, dtype=torch.long)\n",
    "        sensitive_attribute = torch.tensor(user_labels[sens_attr].values, dtype=torch.long)\n",
    "    else:\n",
    "        labels = torch.tensor(filtered_user_labels[label].values, dtype=torch.long)\n",
    "        sensitive_attribute = torch.tensor(filtered_user_labels[sens_attr].values, dtype=torch.long)\n",
    "    \n",
    "    predictions = predictions.float()\n",
    "    labels = labels.float()\n",
    "    sensitive_attribute = sensitive_attribute.float()\n",
    "\n",
    "    def statistical_parity_difference():\n",
    "        prob_group_1 = predictions[sensitive_attribute == 1].mean()\n",
    "        prob_group_0 = predictions[sensitive_attribute == 0].mean()\n",
    "        return abs(prob_group_1 - prob_group_0), prob_group_0, prob_group_1\n",
    "\n",
    "    def equal_opportunity_difference():\n",
    "        tpr_group_1 = predictions[(labels == 1) & (sensitive_attribute == 1)].mean()\n",
    "        tpr_group_0 = predictions[(labels == 1) & (sensitive_attribute == 0)].mean()\n",
    "        return abs(tpr_group_1 - tpr_group_0), tpr_group_0, tpr_group_1\n",
    "\n",
    "    def overall_accuracy_equality_difference():\n",
    "        acc_group_1 = (predictions[sensitive_attribute == 1] == labels[sensitive_attribute == 1]).float().mean()\n",
    "        acc_group_0 = (predictions[sensitive_attribute == 0] == labels[sensitive_attribute == 0]).float().mean()\n",
    "        return abs(acc_group_1 - acc_group_0), acc_group_0, acc_group_1\n",
    "\n",
    "    def treatment_equality_difference():\n",
    "        fn_group_1 = ((predictions == 0) & (labels == 1) & (sensitive_attribute == 1)).sum()\n",
    "        fp_group_1 = ((predictions == 1) & (labels == 0) & (sensitive_attribute == 1)).sum()\n",
    "\n",
    "        fn_group_0 = ((predictions == 0) & (labels == 1) & (sensitive_attribute == 0)).sum()\n",
    "        fp_group_0 = ((predictions == 1) & (labels == 0) & (sensitive_attribute == 0)).sum()\n",
    "\n",
    "        ratio_group_1 = fn_group_1 / fp_group_1 if fp_group_1 != 0 else float('inf')\n",
    "        ratio_group_0 = fn_group_0 / fp_group_0 if fp_group_0 != 0 else float('inf')\n",
    "\n",
    "        return abs(ratio_group_1 - ratio_group_0), ratio_group_0, ratio_group_1, fn_group_1, fp_group_1, fn_group_0, fp_group_0\n",
    "\n",
    "    # Calculating each fairness metric\n",
    "    spd, sp_g0, sp_g1 = statistical_parity_difference()\n",
    "    eod, eod_g0, eod_g1 = equal_opportunity_difference()\n",
    "    oaed, oaed_g0, oaed_g1 = overall_accuracy_equality_difference()\n",
    "    ted, ted_g0, ted_g1, fn_group_1, fp_group_1, fn_group_0, fp_group_0 = treatment_equality_difference()\n",
    "\n",
    "    return {\n",
    "        'Statistical Parity Difference': spd,\n",
    "        'Statistical Parity Group with S=0': sp_g0,\n",
    "        'Statistical Parity Group S=1': sp_g1,\n",
    "        'Equal Opportunity Difference': eod,\n",
    "        'Equal Opportunity Group with S=0': eod_g0,\n",
    "        'Equal Opportunity Group S=1': eod_g1,\n",
    "        'Overall Accuracy Equality Difference': oaed,\n",
    "        'Overall Accuracy Group with S=0': oaed_g0,\n",
    "        'Overall Accuracy Group S=1': oaed_g1,\n",
    "        'Treatment Equality Difference': ted,\n",
    "        'Treatment Equality Group with S=0': ted_g0,\n",
    "        'Treatment Equality Group S=1': ted_g1,\n",
    "        'False Negatives Group 1': fn_group_1,\n",
    "        'False Positives Group 1': fp_group_1,\n",
    "        'False Negatives Group 0': fn_group_0,\n",
    "        'False Positives Group 0': fp_group_0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness(label, predictions, sens_attr='region', balanced=False):\n",
    "    \n",
    "    labels = user_labels[label].values\n",
    "    labels = labels.astype(float)\n",
    "\n",
    "    predictions = predictions.int()\n",
    "    # predictions = predictions.float()\n",
    "\n",
    "    sens_attr_values = user_labels[sens_attr].values\n",
    "    sens_attr_values = sens_attr_values.astype(float)\n",
    "    # labels = label.int()\n",
    "    \n",
    "    # Sensitivity attributes, assuming binary where 0 is unprivileged and 1 is privileged\n",
    "    # sens_attr_values = user_labels[sens_attr].int()\n",
    "    \n",
    "    # Indices for privileged and unprivileged groups\n",
    "    privileged_indices = sens_attr_values == 1\n",
    "    unprivileged_indices = sens_attr_values == 0\n",
    "    \n",
    "    # Calculating metrics for both groups\n",
    "    def calc_metrics(preds, lbls):\n",
    "        tp = ((preds == 1) & (lbls == 1)).sum().item()\n",
    "        tn = ((preds == 0) & (lbls == 0)).sum().item()\n",
    "        fp = ((preds == 1) & (lbls == 0)).sum().item()\n",
    "        fn = ((preds == 0) & (lbls == 1)).sum().item()\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        tpr = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "        \n",
    "        return accuracy, tpr, fpr, fp, fn\n",
    "    \n",
    "    # Metrics for unprivileged\n",
    "    acc_unpriv, tpr_unpriv, _, fp_unpriv, fn_unpriv = calc_metrics(predictions[unprivileged_indices], labels[unprivileged_indices])\n",
    "    # Metrics for privileged\n",
    "    acc_priv, tpr_priv, _, fp_priv, fn_priv = calc_metrics(predictions[privileged_indices], labels[privileged_indices])\n",
    "    \n",
    "    # Calculating fairness metrics\n",
    "    spd = (predictions[privileged_indices].mean() - predictions[unprivileged_indices].mean()).item()\n",
    "    oaed = acc_priv - acc_unpriv\n",
    "    eod = tpr_priv - tpr_unpriv\n",
    "    ted = (fn_unpriv - fn_priv) / (fp_unpriv - fp_priv) if (fp_unpriv - fp_priv) != 0 else float('inf')\n",
    "    \n",
    "    return {\n",
    "        'SPD': spd,\n",
    "        'OAED': oaed,\n",
    "        'EOD': eod,\n",
    "        'Treatment Equality Difference': ted\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness(label, predictions, sens_attr='region', balanced=False):\n",
    "    \n",
    "    labels = user_labels[label].values\n",
    "    # labels = labels.astype(float)\n",
    "\n",
    "    predictions = predictions.int()\n",
    "    # predictions = predictions.float()\n",
    "\n",
    "    sens_attr_values = user_labels[sens_attr].values\n",
    "    # sens_attr_values = sens_attr_values.astype(float)    \n",
    "    \n",
    "    # Indices for privileged and unprivileged groups    \n",
    "    privileged_indices = sens_attr_values == 1\n",
    "    unprivileged_indices = sens_attr_values == 0\n",
    "    \n",
    "    # Calculating metrics for both groups\n",
    "    def calc_metrics(preds, lbls):\n",
    "        tp = ((preds == 1) & (lbls == 1)).sum().item()\n",
    "        tn = ((preds == 0) & (lbls == 0)).sum().item()\n",
    "        fp = ((preds == 1) & (lbls == 0)).sum().item()\n",
    "        fn = ((preds == 0) & (lbls == 1)).sum().item()\n",
    "        \n",
    "        accuracy = (tp + tn) / max(tp + tn + fp + fn, 1)  # Prevent division by zero\n",
    "        tpr = tp / max(tp + fn, 1)  # True Positive Rate\n",
    "        fpr = fp / max(fp + tn, 1)  # False Positive Rate\n",
    "        \n",
    "        return accuracy, tpr, fpr, fp, fn\n",
    "    \n",
    "    # Metrics for unprivileged\n",
    "    acc_unpriv, tpr_unpriv, _, fp_unpriv, fn_unpriv = calc_metrics(predictions[unprivileged_indices], labels[unprivileged_indices])\n",
    "    # Metrics for privileged\n",
    "    acc_priv, tpr_priv, _, fp_priv, fn_priv = calc_metrics(predictions[privileged_indices], labels[privileged_indices])\n",
    "    \n",
    "    # Statistical Parity for both groups\n",
    "    sp_unpriv = predictions[unprivileged_indices].float().mean().item()\n",
    "    sp_priv = predictions[privileged_indices].float().mean().item()\n",
    "    \n",
    "    # Calculating fairness metrics differences\n",
    "    spd = sp_priv - sp_unpriv  # Statistical Parity Difference\n",
    "    oaed = acc_priv - acc_unpriv  # Overall Accuracy Equality Difference\n",
    "    eod = tpr_priv - tpr_unpriv  # Equal Opportunity Difference\n",
    "    \n",
    "    # Treatment Equality for both groups\n",
    "    ted_unpriv = fp_unpriv / max(fn_unpriv, 1) if fn_unpriv != 0 else float('inf')  # Avoid division by zero\n",
    "    ted_priv = fp_priv / max(fn_priv, 1) if fn_priv != 0 else float('inf')\n",
    "    ted_diff = ted_unpriv - ted_priv  # Difference in Treatment Equality\n",
    "\n",
    "    unique, counts = torch.unique(predictions, return_counts=True)\n",
    "    prediction_distribution = dict(zip(unique.tolist(), counts.tolist()))\n",
    "\n",
    "    print(\"Prediction Distribution:\", prediction_distribution)\n",
    "    \n",
    "    privileged_preds = predictions[sens_attr_values == 1]\n",
    "    unprivileged_preds = predictions[sens_attr_values == 0]\n",
    "\n",
    "    # Analyze distribution for privileged group\n",
    "    priv_unique, priv_counts = torch.unique(privileged_preds, return_counts=True)\n",
    "    priv_distribution = dict(zip(priv_unique.tolist(), priv_counts.tolist()))\n",
    "\n",
    "    # Analyze distribution for unprivileged group\n",
    "    unpriv_unique, unpriv_counts = torch.unique(unprivileged_preds, return_counts=True)\n",
    "    unpriv_distribution = dict(zip(unpriv_unique.tolist(), unpriv_counts.tolist()))\n",
    "\n",
    "    print(\"Privileged Prediction Distribution:\", priv_distribution)\n",
    "    print(\"Unprivileged Prediction Distribution:\", unpriv_distribution)\n",
    "\n",
    "    priv_positive_rate = privileged_preds.float().mean().item()\n",
    "    unpriv_positive_rate = unprivileged_preds.float().mean().item()\n",
    "\n",
    "    print(\"Privileged Positive Prediction Rate:\", priv_positive_rate)\n",
    "    print(\"Unprivileged Positive Prediction Rate:\", unpriv_positive_rate)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'SPD': spd,\n",
    "        'OAED': oaed,\n",
    "        'EOD': eod,\n",
    "        'Treatment Equality Difference': ted_diff,\n",
    "        'SP_Unprivileged': sp_unpriv,\n",
    "        'SP_Privileged': sp_priv,\n",
    "        'OAED_Unprivileged': acc_unpriv,\n",
    "        'OAED_Privileged': acc_priv,\n",
    "        'EOD_Unprivileged': tpr_unpriv,\n",
    "        'EOD_Privileged': tpr_priv,\n",
    "        'TED_Unprivileged': ted_unpriv,\n",
    "        'TED_Privileged': ted_priv\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def training(model, data, optimizer, epochs, fairness=False, alpha=0, beta=0, gamma=0, delta=0):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        \n",
    "        if fairness:\n",
    "            loss = fairness_aware_loss(out[data.train_mask], data, data.x[data.train_mask, -1],\n",
    "                                       alpha=alpha, beta=beta, gamma=gamma, delta=delta)\n",
    "            \n",
    "        else:\n",
    "            # criterion = torch.nn.CrossEntropyLoss()\n",
    "            # criterion = torch.nn.BCELoss()\n",
    "            criterion = torch.nn.NLLLoss()\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch} | Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test(model, data, balanced=False):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      out = model(data.x, data.edge_index)\n",
    "\n",
    "    _, pred = model(data.x, data.edge_index).max(dim=1)\n",
    "    correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    accuracy = correct / int(data.test_mask.sum())\n",
    "    # print(f'Accuracy: {accuracy}')\n",
    "\n",
    "    # Convert model outputs to binary predictions\n",
    "    predictions = out.argmax(dim=1)\n",
    "    # print(predictions[0:20])\n",
    "    \n",
    "    # unique, counts = torch.unique(predictions, return_counts=True)\n",
    "    # prediction_distribution = dict(zip(unique.tolist(), counts.tolist()))\n",
    "\n",
    "    # print(\"Prediction Distribution:\", prediction_distribution)\n",
    "\n",
    "    fairness_metrics = calculate_fairness(label='I_am_working_in_field', predictions=predictions, sens_attr='region', balanced=balanced)\n",
    "    fairness_metrics['Accuracy'] = accuracy\n",
    "    # # Print the fairness metrics\n",
    "    # for metric, value in fairness_metrics.items():\n",
    "    #     print(f\"{metric}: {value}\")\n",
    "\n",
    "    return fairness_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(metrics):\n",
    "    count = -1\n",
    "\n",
    "    for key, value in metrics.items():\n",
    "        count += 1\n",
    "        if count == 3:\n",
    "            print(f\"\\n\\n{key} : {value:.5f}\")\n",
    "            count = 0\n",
    "        else:\n",
    "            print(f\"{key} : {value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN class that takes in the data as an input for dimensions of the convolutions\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, x, edge_index):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index, *args, **kwargs):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # x = F.softmax(x, dim=1)\n",
    "        # return x\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss function and optimizer\n",
    "gcn_model = GCN(data.x, data.edge_index)\n",
    "gcn_optimizer = torch.optim.SGD(gcn_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 3.049299716949463\n",
      "Epoch 10 | Loss: 0.4464818835258484\n",
      "Epoch 20 | Loss: 0.4458039104938507\n",
      "Epoch 30 | Loss: 0.44517987966537476\n",
      "Epoch 40 | Loss: 0.44460198283195496\n"
     ]
    }
   ],
   "source": [
    "# Train the first model: GCN, standard data, NLL loss\n",
    "training(model=gcn_model, data=data, optimizer=gcn_optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the standard GCN model with the standard NLL loss: \n",
      "Prediction Distribution: {0: 65626, 1: 943}\n",
      "Privileged Prediction Distribution: {0: 18877, 1: 354}\n",
      "Unprivileged Prediction Distribution: {0: 46749, 1: 589}\n",
      "Privileged Positive Prediction Rate: 0.018407778814435005\n",
      "Unprivileged Positive Prediction Rate: 0.012442435137927532\n",
      "\n",
      "SPD : 0.00597\n",
      "OAED : -0.02498\n",
      "EOD : 0.00252\n",
      "\n",
      "\n",
      "Treatment Equality Difference : -0.02509\n",
      "SP_Unprivileged : 0.01244\n",
      "SP_Privileged : 0.01841\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.86607\n",
      "OAED_Privileged : 0.84109\n",
      "EOD_Unprivileged : 0.01874\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.02126\n",
      "TED_Unprivileged : 0.08136\n",
      "TED_Privileged : 0.10644\n",
      "\n",
      "\n",
      "Accuracy : 0.86157\n"
     ]
    }
   ],
   "source": [
    "# Test the first model: GCN, standard data, NLL loss\n",
    "print(\"Here are the values for the standard GCN model with the standard NLL loss: \")\n",
    "\n",
    "metrics_base_gcn_model = test(gcn_model, data)\n",
    "print()\n",
    "print_metrics(metrics_base_gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the standard GCN model with the standard NLL loss: \n",
      "Prediction Distribution: {0: 64865, 1: 1704}\n",
      "Privileged Prediction Distribution: {0: 18833, 1: 398}\n",
      "Unprivileged Prediction Distribution: {0: 46032, 1: 1306}\n",
      "Privileged Positive Prediction Rate: 0.020695751532912254\n",
      "Unprivileged Positive Prediction Rate: 0.027588829398155212\n",
      "\n",
      "SPD : -0.00689\n",
      "OAED : -0.01427\n",
      "EOD : -0.00439\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.07490\n",
      "SP_Unprivileged : 0.02759\n",
      "SP_Privileged : 0.02070\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.85016\n",
      "OAED_Privileged : 0.83589\n",
      "EOD_Unprivileged : 0.01573\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.01134\n",
      "TED_Unprivileged : 0.20609\n",
      "TED_Privileged : 0.13118\n",
      "\n",
      "\n",
      "Accuracy : 0.84926\n"
     ]
    }
   ],
   "source": [
    "# Test the first model: GCN, standard data, NLL loss\n",
    "print(\"Here are the values for the standard GCN model with the standard NLL loss: \")\n",
    "\n",
    "metrics_base_gcn_model = test(gcn_model, data)\n",
    "print()\n",
    "print_metrics(metrics_base_gcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=gcn_model,\n",
    "    algorithm=GNNExplainer(epochs=50),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='log_probs', \n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3848, 0.3813, 0.3852,  ..., 0.3848, 0.3817, 0.3818])\n",
      "tensor([[0.3927, 0.5484, 0.3853,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4342, 0.4323,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3502, 0.6290, 0.3634,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.4088, 0.5337, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3690, 0.6241, 0.4436,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.3814, 0.4026, 0.3996,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer(data.x, edge_index)\n",
    "print(explanation.edge_mask)\n",
    "print(explanation.node_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>public</th>\n",
       "      <th>completion_percentage</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>AGE</th>\n",
       "      <th>I_am_working_in_field</th>\n",
       "      <th>spoken_languages_indicator</th>\n",
       "      <th>anglicky</th>\n",
       "      <th>nemecky</th>\n",
       "      <th>...</th>\n",
       "      <th>odbornu literaturu</th>\n",
       "      <th>psychologicku literaturu</th>\n",
       "      <th>literaturu pre rozvoj osobnosti</th>\n",
       "      <th>cestopisy</th>\n",
       "      <th>literaturu faktu</th>\n",
       "      <th>poeziu</th>\n",
       "      <th>zivotopisne a pamate</th>\n",
       "      <th>pocitacovu literaturu</th>\n",
       "      <th>filozoficku literaturu</th>\n",
       "      <th>literaturu o umeni a architekture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131075</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67791</th>\n",
       "      <td>1572848</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67792</th>\n",
       "      <td>917493</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67793</th>\n",
       "      <td>1572853</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67794</th>\n",
       "      <td>1572859</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67795</th>\n",
       "      <td>393212</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67796 rows Ã— 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  public  completion_percentage  gender  region   AGE  \\\n",
       "0            1       1                     14     1.0       0  26.0   \n",
       "1       131075       0                     33     1.0       1  25.0   \n",
       "2            5       1                     66     1.0       0  26.0   \n",
       "3            6       0                     22     0.0       0  38.0   \n",
       "4            7       1                     12     0.0       1  22.0   \n",
       "...        ...     ...                    ...     ...     ...   ...   \n",
       "67791  1572848       1                     12     1.0       1  34.0   \n",
       "67792   917493       1                     60     1.0       0  15.0   \n",
       "67793  1572853       1                     12     0.0       1  52.0   \n",
       "67794  1572859       1                     47     1.0       0   0.0   \n",
       "67795   393212       1                     12     1.0       1  33.0   \n",
       "\n",
       "       I_am_working_in_field  spoken_languages_indicator  anglicky  nemecky  \\\n",
       "0                          0                           1         1        0   \n",
       "1                          0                           1         0        1   \n",
       "2                          1                           1         1        1   \n",
       "3                          0                           0         0        0   \n",
       "4                          0                           0         0        0   \n",
       "...                      ...                         ...       ...      ...   \n",
       "67791                      0                           0         0        0   \n",
       "67792                      1                           1         1        0   \n",
       "67793                      0                           0         0        0   \n",
       "67794                      1                           0         0        0   \n",
       "67795                      0                           0         0        0   \n",
       "\n",
       "       ...  odbornu literaturu  psychologicku literaturu  \\\n",
       "0      ...                   0                         0   \n",
       "1      ...                   0                         0   \n",
       "2      ...                   0                         0   \n",
       "3      ...                   0                         0   \n",
       "4      ...                   0                         0   \n",
       "...    ...                 ...                       ...   \n",
       "67791  ...                   0                         0   \n",
       "67792  ...                   0                         0   \n",
       "67793  ...                   0                         0   \n",
       "67794  ...                   0                         0   \n",
       "67795  ...                   0                         0   \n",
       "\n",
       "       literaturu pre rozvoj osobnosti  cestopisy  literaturu faktu  poeziu  \\\n",
       "0                                    0          0                 0       0   \n",
       "1                                    0          0                 0       0   \n",
       "2                                    0          0                 0       0   \n",
       "3                                    0          0                 0       0   \n",
       "4                                    0          0                 0       0   \n",
       "...                                ...        ...               ...     ...   \n",
       "67791                                0          0                 0       0   \n",
       "67792                                0          0                 0       0   \n",
       "67793                                0          0                 0       0   \n",
       "67794                                0          0                 0       0   \n",
       "67795                                0          0                 0       0   \n",
       "\n",
       "       zivotopisne a pamate  pocitacovu literaturu  filozoficku literaturu  \\\n",
       "0                         0                      0                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         0                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "...                     ...                    ...                     ...   \n",
       "67791                     0                      0                       0   \n",
       "67792                     0                      0                       0   \n",
       "67793                     0                      0                       0   \n",
       "67794                     0                      0                       0   \n",
       "67795                     0                      0                       0   \n",
       "\n",
       "       literaturu o umeni a architekture  \n",
       "0                                      0  \n",
       "1                                      0  \n",
       "2                                      0  \n",
       "3                                      0  \n",
       "4                                      0  \n",
       "...                                  ...  \n",
       "67791                                  0  \n",
       "67792                                  0  \n",
       "67793                                  0  \n",
       "67794                                  0  \n",
       "67795                                  0  \n",
       "\n",
       "[67796 rows x 279 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explanation.visualize_feature_importance(top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fair Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairnessAwareMessagePassingLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FairnessAwareMessagePassingLayer, self).__init__(aggr='mean')  \n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.a_fair = nn.Parameter(torch.rand(out_channels)) \n",
    "        self.sensitive_attr = torch.tensor(user_labels['region'].values, dtype=torch.float) \n",
    "        self.bias_correction = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Add self-loops \n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "    \n",
    "    def message(self, x_j, edge_index, size):\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Compute statistical parity difference for each edge\n",
    "        group_difference = self.sensitive_attr[row] - self.sensitive_attr[col]\n",
    "        \n",
    "        # Adjust messages based on statistical parity\n",
    "        fairness_adjustment = (1 + self.bias_correction * group_difference.view(-1, 1))\n",
    "\n",
    "        return fairness_adjustment * norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_GCN(torch.nn.Module):\n",
    "    def __init__(self, data):\n",
    "        super(custom_GCN, self).__init__()\n",
    "        self.conv1 = FairnessAwareMessagePassingLayer(data.num_node_features, 16)\n",
    "        self.conv2 = FairnessAwareMessagePassingLayer(16, 2) # 2 output classes for gender\n",
    "\n",
    "    def forward(self, x, edge_index, *args, **kwargs):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Fair Model\n",
    "\n",
    "This model is an instantiation of the `custom_GCN` using the standard cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.optim.SGD: Stochastic Gradient Descent optimizer.\n",
    "# torch.optim.Adam: Adam optimizer.\n",
    "# torch.optim.Adagrad: Adagrad optimizer.\n",
    "# torch.optim.Adadelta: Adadelta optimizer.\n",
    "# torch.optim.RMSprop: RMSprop optimizer.\n",
    "# torch.optim.AdamW: AdamW optimizer.\n",
    "# torch.optim.SparseAdam: SparseAdam optimizer.\n",
    "# torch.optim.LBFGS: L-BFGS optimizer.\n",
    "# torch.optim.Rprop: Rprop optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.6828877329826355\n",
      "Epoch 10 | Loss: 0.6807765364646912\n",
      "Epoch 20 | Loss: 0.6787249445915222\n",
      "Epoch 30 | Loss: 0.6767349243164062\n",
      "Epoch 40 | Loss: 0.674805760383606\n",
      "Epoch 50 | Loss: 0.6729360222816467\n",
      "Epoch 60 | Loss: 0.6711239814758301\n",
      "Epoch 70 | Loss: 0.6693678498268127\n",
      "Epoch 80 | Loss: 0.6676660180091858\n",
      "Epoch 90 | Loss: 0.6660498976707458\n"
     ]
    }
   ],
   "source": [
    "model2 = custom_GCN(data)\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model: Custom MP GNN, cross-entropy loss\n",
    "training(model=model2, data=data, optimizer=optimizer2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the standard cross-entropy loss: \n",
      "Prediction Distribution: {0: 66502, 1: 67}\n",
      "Privileged Prediction Distribution: {0: 19215, 1: 16}\n",
      "Unprivileged Prediction Distribution: {0: 47287, 1: 51}\n",
      "Privileged Positive Prediction Rate: 0.0008319900371134281\n",
      "Unprivileged Positive Prediction Rate: 0.0010773586109280586\n",
      "\n",
      "SPD : -0.00025\n",
      "OAED : -0.02028\n",
      "EOD : 0.00000\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.00287\n",
      "SP_Unprivileged : 0.00108\n",
      "SP_Privileged : 0.00083\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.87270\n",
      "OAED_Privileged : 0.85243\n",
      "EOD_Unprivileged : 0.00000\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.00000\n",
      "TED_Unprivileged : 0.00854\n",
      "TED_Privileged : 0.00567\n",
      "\n",
      "\n",
      "Accuracy : 0.87021\n"
     ]
    }
   ],
   "source": [
    "# Test the first FAIR model: CustomGNN, cross-entropy loss\n",
    "print(\"Here are the values for the CustomGNN model with the standard cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gnn_model_1 = test(model2, data)\n",
    "print()\n",
    "print_metrics(metrics_custom_gnn_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the standard cross-entropy loss: \n",
      "Prediction Distribution: {0: 64476, 1: 2093}\n",
      "Privileged Prediction Distribution: {0: 18688, 1: 543}\n",
      "Unprivileged Prediction Distribution: {0: 45788, 1: 1550}\n",
      "Privileged Positive Prediction Rate: 0.0282356608659029\n",
      "Unprivileged Positive Prediction Rate: 0.03274324908852577\n",
      "\n",
      "SPD : -0.00451\n",
      "OAED : -0.01592\n",
      "EOD : -0.00315\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.06603\n",
      "SP_Unprivileged : 0.03274\n",
      "SP_Privileged : 0.02824\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.84729\n",
      "OAED_Privileged : 0.83137\n",
      "EOD_Unprivileged : 0.02477\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.02162\n",
      "TED_Unprivileged : 0.24060\n",
      "TED_Privileged : 0.17457\n",
      "\n",
      "\n",
      "Accuracy : 0.84467\n"
     ]
    }
   ],
   "source": [
    "# Test the first FAIR model: CustomGNN, cross-entropy loss\n",
    "print(\"Here are the values for the CustomGNN model with the standard cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gnn_model_1 = test(model2, data)\n",
    "print()\n",
    "print_metrics(metrics_custom_gnn_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPD : -0.00689\n",
    "OAED : -0.01427\n",
    "EOD : -0.00439\n",
    "\n",
    "\n",
    "Treatment Equality Difference : 0.07490\n",
    "SP_Unprivileged : 0.02759\n",
    "SP_Privileged : 0.02070\n",
    "\n",
    "\n",
    "OAED_Unprivileged : 0.85016\n",
    "OAED_Privileged : 0.83589\n",
    "EOD_Unprivileged : 0.01573\n",
    "\n",
    "\n",
    "EOD_Privileged : 0.01134\n",
    "TED_Unprivileged : 0.20609\n",
    "TED_Privileged : 0.13118\n",
    "\n",
    "\n",
    "Accuracy : 0.84926"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Fair Model\n",
    "\n",
    "This model is an instantiation of the `custom_GCN` using the fair cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.40859881043434143\n",
      "Epoch 10 | Loss: 0.40833157300949097\n",
      "Epoch 20 | Loss: 0.4080710709095001\n",
      "Epoch 30 | Loss: 0.4078168570995331\n",
      "Epoch 40 | Loss: 0.40756848454475403\n",
      "Epoch 50 | Loss: 0.4073258936405182\n",
      "Epoch 60 | Loss: 0.40708935260772705\n",
      "Epoch 70 | Loss: 0.4068576991558075\n",
      "Epoch 80 | Loss: 0.4066312611103058\n",
      "Epoch 90 | Loss: 0.40641066431999207\n"
     ]
    }
   ],
   "source": [
    "custom_gnn_model_2 = custom_GCN(data)\n",
    "optimizer_custom_gnn_model_2 = torch.optim.SGD(custom_gnn_model_2.parameters(), lr=0.001)\n",
    "\n",
    "fairness=True\n",
    "alpha, beta, gamma, delta = 0.1, 0.1, 0.1, 0.1\n",
    "\n",
    "# Train the model: Custom MP GNN, FAIR cross-entropy loss\n",
    "training(model=custom_gnn_model_2, \n",
    "         data=data, \n",
    "         optimizer=optimizer_custom_gnn_model_2, \n",
    "         fairness=fairness, \n",
    "         alpha=alpha, \n",
    "         beta=beta, \n",
    "         gamma=gamma, \n",
    "         delta=delta, \n",
    "         epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the FAIR standard cross-entropy loss: \n",
      "Prediction Distribution: {0: 65789, 1: 780}\n",
      "Privileged Prediction Distribution: {0: 19055, 1: 176}\n",
      "Unprivileged Prediction Distribution: {0: 46734, 1: 604}\n",
      "Privileged Positive Prediction Rate: 0.009151889942586422\n",
      "Unprivileged Positive Prediction Rate: 0.012759305536746979\n",
      "\n",
      "SPD : -0.00361\n",
      "OAED : -0.01732\n",
      "EOD : -0.00491\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.03490\n",
      "SP_Unprivileged : 0.01276\n",
      "SP_Privileged : 0.00915\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.86736\n",
      "OAED_Privileged : 0.85003\n",
      "EOD_Unprivileged : 0.02510\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.02020\n",
      "TED_Unprivileged : 0.07794\n",
      "TED_Privileged : 0.04304\n",
      "\n",
      "\n",
      "Accuracy : 0.86608\n"
     ]
    }
   ],
   "source": [
    "# Test the second FAIR model: CustomGNN, FAIR cross-entropy loss\n",
    "print(\"Here are the values for the CustomGNN model with the FAIR standard cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gnn_model_2 = test(custom_gnn_model_2, data)\n",
    "print()\n",
    "print_metrics(metrics_custom_gnn_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third FAIR Model\n",
    "\n",
    "This model is an instantiation of the `custom_GCN` using the fair cross-entropy loss using ONLY large treatment equality penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.41925954818725586\n",
      "Epoch 10 | Loss: 0.41869571805000305\n",
      "Epoch 20 | Loss: 0.41815832257270813\n",
      "Epoch 30 | Loss: 0.4176436960697174\n",
      "Epoch 40 | Loss: 0.41715067625045776\n",
      "Epoch 50 | Loss: 0.41667720675468445\n",
      "Epoch 60 | Loss: 0.41622015833854675\n",
      "Epoch 70 | Loss: 0.4157787263393402\n",
      "Epoch 80 | Loss: 0.415351003408432\n",
      "Epoch 90 | Loss: 0.41493579745292664\n"
     ]
    }
   ],
   "source": [
    "custom_gnn_model_3 = custom_GCN(data)\n",
    "optimizer_custom_gnn_model_3 = torch.optim.SGD(custom_gnn_model_3.parameters(), lr=0.001)\n",
    "\n",
    "fairness=True\n",
    "alpha, beta, gamma, delta = 0, 0.4, 0, 0\n",
    "\n",
    "# Train the model: Custom MP GNN, FAIR cross-entropy loss\n",
    "training(model=custom_gnn_model_3, \n",
    "         data=data, \n",
    "         optimizer=optimizer_custom_gnn_model_3, \n",
    "         fairness=fairness, \n",
    "         alpha=alpha, \n",
    "         beta=beta, \n",
    "         gamma=gamma, \n",
    "         delta=delta, \n",
    "         epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGNN model with the FAIR standard cross-entropy loss with LARGE TE penalty: \n",
      "Prediction Distribution: {0: 58586, 1: 7983}\n",
      "Privileged Prediction Distribution: {0: 17186, 1: 2045}\n",
      "Unprivileged Prediction Distribution: {0: 41400, 1: 5938}\n",
      "Privileged Positive Prediction Rate: 0.10633872449398041\n",
      "Unprivileged Positive Prediction Rate: 0.12543833255767822\n",
      "\n",
      "SPD : -0.01910\n",
      "OAED : -0.00640\n",
      "EOD : -0.04346\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.31477\n",
      "SP_Unprivileged : 0.12544\n",
      "SP_Privileged : 0.10634\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.79617\n",
      "OAED_Privileged : 0.78977\n",
      "EOD_Unprivileged : 0.18946\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.14600\n",
      "TED_Unprivileged : 0.99236\n",
      "TED_Privileged : 0.67759\n",
      "\n",
      "\n",
      "Accuracy : 0.79473\n"
     ]
    }
   ],
   "source": [
    "# Test the third FAIR model: CustomGNN, FAIR cross-entropy loss with LARGE TE penalty\n",
    "print(\"Here are the values for the CustomGNN model with the FAIR standard cross-entropy loss with LARGE TE penalty: \")\n",
    "\n",
    "metrics_custom_gnn_model_3 = test(custom_gnn_model_3, data)\n",
    "print()\n",
    "print_metrics(metrics_custom_gnn_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention-based Message Passing\n",
    "\n",
    "In this section, the models are trained using a custom attention-based message passing model.  \n",
    "This custom attention should take the sensitive attribute into consideration when calculating the attention weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline GAT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT class that takes in the data as an input for dimensions of the convolutions\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, x, edge_index):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(data.num_node_features, 16)\n",
    "        self.conv2 = GATConv(16, 2) # 2 output classes for gender\n",
    "\n",
    "    def forward(self, x , edge_index, *args, **kwargs):\n",
    "        # x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss function and optimizer\n",
    "gat_model = GAT(data.x, data.edge_index)\n",
    "gat_optimizer = torch.optim.AdamW(gat_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.5376834273338318\n",
      "Epoch 10 | Loss: 0.39578431844711304\n",
      "Epoch 20 | Loss: 0.38350555300712585\n",
      "Epoch 30 | Loss: 0.37733596563339233\n",
      "Epoch 40 | Loss: 0.37202683091163635\n"
     ]
    }
   ],
   "source": [
    "training(model=gat_model, data=data, optimizer=gat_optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the standard GAT model with the standard cross-entropy loss: \n",
      "Prediction Distribution: {0: 66130, 1: 439}\n",
      "Privileged Prediction Distribution: {0: 19080, 1: 151}\n",
      "Unprivileged Prediction Distribution: {0: 47050, 1: 288}\n",
      "Privileged Positive Prediction Rate: 0.00785190612077713\n",
      "Unprivileged Positive Prediction Rate: 0.006083907093852758\n",
      "\n",
      "SPD : 0.00177\n",
      "OAED : -0.01961\n",
      "EOD : 0.00594\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.00049\n",
      "SP_Unprivileged : 0.00608\n",
      "SP_Privileged : 0.00785\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.87344\n",
      "OAED_Privileged : 0.85383\n",
      "EOD_Unprivileged : 0.02276\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.02870\n",
      "TED_Unprivileged : 0.02603\n",
      "TED_Privileged : 0.02554\n",
      "\n",
      "\n",
      "Accuracy : 0.87141\n"
     ]
    }
   ],
   "source": [
    "# Test the first model: GAT, standard data, cross-entropy loss\n",
    "print(\"Here are the values for the standard GAT model with the standard cross-entropy loss: \")\n",
    "\n",
    "metrics_base_gat_model = test(gat_model, data)\n",
    "print()\n",
    "print_metrics(metrics_base_gat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FairMP GAT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "class Attention_FairMessagePassing(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Attention_FairMessagePassing, self).__init__(aggr='mean')\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.att = nn.Linear(out_channels, 1)\n",
    "        self.sensitive_attr = torch.tensor(user_labels['region'].values, dtype=torch.float)\n",
    "        self.bias_correction = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Add self-loops\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        x = self.lin(x)\n",
    "        x = self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # Calculate attention weights\n",
    "        alpha = self.att(torch.abs(x_i - x_j))\n",
    "        alpha = torch.exp(alpha) / (torch.exp(alpha).sum(dim=1, keepdim=True) + self.bias_correction)\n",
    "\n",
    "        # Apply attention weights to messages\n",
    "        return x_j * alpha\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT class that takes in the data as an input for dimensions of the convolutions\n",
    "class CustomGAT(torch.nn.Module):\n",
    "    def __init__(self, x, edge_index):\n",
    "        super(CustomGAT, self).__init__()\n",
    "        self.conv1 = Attention_FairMessagePassing(data.num_node_features, 16)\n",
    "        self.conv2 = Attention_FairMessagePassing(16, 2) # 2 output classes for gender\n",
    "\n",
    "    def forward(self, x , edge_index, *args, **kwargs):\n",
    "        # x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Fair GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss function and optimizer\n",
    "custom_gat_model = CustomGAT(data.x, data.edge_index)\n",
    "custom_gat_optimizer = torch.optim.AdamW(custom_gat_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.45256906747817993\n",
      "Epoch 10 | Loss: 0.39204564690589905\n",
      "Epoch 20 | Loss: 0.38255640864372253\n",
      "Epoch 30 | Loss: 0.37586042284965515\n",
      "Epoch 40 | Loss: 0.3703364133834839\n"
     ]
    }
   ],
   "source": [
    "training(model=custom_gat_model, data=data, optimizer=custom_gat_optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGAT model with the standard cross-entropy loss: \n",
      "Prediction Distribution: {0: 66139, 1: 430}\n",
      "Privileged Prediction Distribution: {0: 19111, 1: 120}\n",
      "Unprivileged Prediction Distribution: {0: 47028, 1: 310}\n",
      "Privileged Positive Prediction Rate: 0.006239925045520067\n",
      "Unprivileged Positive Prediction Rate: 0.006548650097101927\n",
      "\n",
      "SPD : -0.00031\n",
      "OAED : -0.01993\n",
      "EOD : -0.00234\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.00724\n",
      "SP_Unprivileged : 0.00655\n",
      "SP_Privileged : 0.00624\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.87319\n",
      "OAED_Privileged : 0.85326\n",
      "EOD_Unprivileged : 0.02360\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.02126\n",
      "TED_Unprivileged : 0.02897\n",
      "TED_Privileged : 0.02172\n",
      "\n",
      "\n",
      "Accuracy : 0.87186\n"
     ]
    }
   ],
   "source": [
    "# Test the first model: CustomGAT, standard data, cross-entropy loss\n",
    "print(\"Here are the values for the CustomGAT model with the standard cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gat_model = test(custom_gat_model, data)\n",
    "print()\n",
    "print_metrics(metrics_custom_gat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPD : 0.00177\n",
    "# OAED : -0.01961\n",
    "# EOD : 0.00594\n",
    "\n",
    "\n",
    "# Treatment Equality Difference : 0.00049\n",
    "# SP_Unprivileged : 0.00608\n",
    "# SP_Privileged : 0.00785\n",
    "\n",
    "\n",
    "# OAED_Unprivileged : 0.87344\n",
    "# OAED_Privileged : 0.85383\n",
    "# EOD_Unprivileged : 0.02276\n",
    "\n",
    "\n",
    "# EOD_Privileged : 0.02870\n",
    "# TED_Unprivileged : 0.02603\n",
    "# TED_Privileged : 0.02554\n",
    "\n",
    "\n",
    "# Accuracy : 0.87141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPD : 0.00009\n",
    "# OAED : -0.02074\n",
    "# EOD : -0.00063\n",
    "\n",
    "\n",
    "# Treatment Equality Difference : -0.00081\n",
    "# SP_Unprivileged : 0.00038\n",
    "# SP_Privileged : 0.00047\n",
    "\n",
    "\n",
    "# OAED_Unprivileged : 0.87374\n",
    "# OAED_Privileged : 0.85300\n",
    "# EOD_Unprivileged : 0.00134\n",
    "\n",
    "\n",
    "# EOD_Privileged : 0.00071\n",
    "# TED_Unprivileged : 0.00168\n",
    "# TED_Privileged : 0.00248\n",
    "\n",
    "\n",
    "# Accuracy : 0.87171"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Fair GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model, define loss function and optimizer\n",
    "custom_gat_model_2 = CustomGAT(data.x, data.edge_index)\n",
    "custom_gat_optimizer_2 = torch.optim.AdamW(custom_gat_model_2.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.5545613169670105\n",
      "Epoch 10 | Loss: 0.3832014501094818\n",
      "Epoch 20 | Loss: 0.35803094506263733\n",
      "Epoch 30 | Loss: 0.3484097123146057\n",
      "Epoch 40 | Loss: 0.34348684549331665\n"
     ]
    }
   ],
   "source": [
    "training(model=custom_gat_model_2, data=data, optimizer=custom_gat_optimizer_2, fairness=True, beta=0.1, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGAT model with the FAIR cross-entropy loss: \n",
      "Prediction Distribution: {0: 66282, 1: 287}\n",
      "Privileged Prediction Distribution: {0: 19156, 1: 75}\n",
      "Unprivileged Prediction Distribution: {0: 47126, 1: 212}\n",
      "Privileged Positive Prediction Rate: 0.003899953095242381\n",
      "Unprivileged Positive Prediction Rate: 0.004478431772440672\n",
      "SPD : -0.00058\n",
      "OAED : -0.01979\n",
      "EOD : -0.00134\n",
      "\n",
      "\n",
      "Treatment Equality Difference : 0.00769\n",
      "SP_Unprivileged : 0.00448\n",
      "SP_Privileged : 0.00390\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.87268\n",
      "OAED_Privileged : 0.85289\n",
      "EOD_Unprivileged : 0.01339\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.01205\n",
      "TED_Unprivileged : 0.02239\n",
      "TED_Privileged : 0.01471\n",
      "\n",
      "\n",
      "Accuracy : 0.87149\n"
     ]
    }
   ],
   "source": [
    "# Test the second model: CustomGAT, FAIR cross-entropy loss\n",
    "print(\"Here are the values for the CustomGAT model with the FAIR cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gat_model_2 = test(custom_gat_model_2, data)\n",
    "\n",
    "print_metrics(metrics_custom_gat_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the values for the CustomGAT model with the FAIR cross-entropy loss: \n",
      "Prediction Distribution: {0: 66542, 1: 27}\n",
      "Privileged Prediction Distribution: {0: 19222, 1: 9}\n",
      "Unprivileged Prediction Distribution: {0: 47320, 1: 18}\n",
      "Privileged Positive Prediction Rate: 0.0004679943958763033\n",
      "Unprivileged Positive Prediction Rate: 0.0003802441933657974\n",
      "SPD : 0.00009\n",
      "OAED : -0.02074\n",
      "EOD : -0.00063\n",
      "\n",
      "\n",
      "Treatment Equality Difference : -0.00081\n",
      "SP_Unprivileged : 0.00038\n",
      "SP_Privileged : 0.00047\n",
      "\n",
      "\n",
      "OAED_Unprivileged : 0.87374\n",
      "OAED_Privileged : 0.85300\n",
      "EOD_Unprivileged : 0.00134\n",
      "\n",
      "\n",
      "EOD_Privileged : 0.00071\n",
      "TED_Unprivileged : 0.00168\n",
      "TED_Privileged : 0.00248\n",
      "\n",
      "\n",
      "Accuracy : 0.87171\n"
     ]
    }
   ],
   "source": [
    "# Test the second model: CustomGAT, FAIR cross-entropy loss\n",
    "print(\"Here are the values for the CustomGAT model with the FAIR cross-entropy loss: \")\n",
    "\n",
    "metrics_custom_gat_model_2 = test(custom_gat_model_2, data)\n",
    "\n",
    "print_metrics(metrics_custom_gat_model_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
